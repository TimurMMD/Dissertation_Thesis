{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDOoGEsTqfgldNdmZJdMWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimurMMD/Dissertation_Thesis/blob/main/TabNet_return.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgl609862Qxl",
        "outputId": "0e3ce1e5-e02e-49d8-e5ee-41c72ce75584"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.66.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch_tabnet\n",
            "Successfully installed pytorch_tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "L4VQ8qGowgjB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "import torch\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "## Load the Dataset: Import data into a pandas DataFrame.\n",
        "## Handle Missing Data: Fill any missing values (e.g., with forward or backward fill, or by using the mean).\n",
        "## Drop Non-Predictive Columns: Remove any columns that are not predictive, such as dates or IDs."
      ],
      "metadata": {
        "id": "vjFHUWD-zwob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file name you uploaded\n",
        "zip_file = '/content/financial_data_refine_changed.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/csv_files_refine')\n",
        "\n",
        "# Check files\n",
        "os.listdir('/content/csv_files_refine')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8gv9ILl1wxU0",
        "outputId": "2927868c-6340-4952-ab02-0f41ac0dc33c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['financial_data_refine']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the folder where the CSVs are located\n",
        "path = '/content/csv_files_refine/financial_data_refine'\n",
        "\n",
        "# Get all CSV file paths with *_final.csv pattern\n",
        "all_files = glob.glob(path + \"/*_final.csv\")\n",
        "\n",
        "# Combine all CSVs into one DataFrame, adding the 'ticker' column\n",
        "combined_df = pd.concat((pd.read_csv(f).assign(ticker=f.split('/')[-1].split('_final')[0]) for f in all_files), ignore_index=True)\n",
        "\n",
        "# Check the combined dataset\n",
        "print(combined_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy-z6IrCw-wD",
        "outputId": "0f19f828-7300-46f0-9d83-fa1ab8c89fd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date  freeCashFlow  current_ratio  quick_ratio  debt_to_equity  \\\n",
            "0  2020-03-31 -1.278000e+09       0.671127     0.452011        2.386756   \n",
            "1  2020-06-30 -4.680000e+08       0.553445     0.356381        2.494020   \n",
            "2  2020-09-30  1.104000e+09       0.519919     0.328820        2.480416   \n",
            "3  2020-12-31 -4.090000e+08       0.532475     0.338240        2.360187   \n",
            "4  2021-03-31 -1.270000e+08       0.490856     0.313391        2.361827   \n",
            "\n",
            "   interest_coverage_ratio  gross_profit_margin  operating_income_margin  \\\n",
            "0                 2.865699             0.498235                 0.250126   \n",
            "1                -1.182310             0.490684                 0.217119   \n",
            "2                 3.614943             0.503050                 0.269900   \n",
            "3                 2.175701             0.443829                 0.012809   \n",
            "4                 2.915888             0.492520                 0.235772   \n",
            "\n",
            "   net_profit_margin       ROA       ROE  asset_turnover_ratio  \\\n",
            "0           0.157674  0.005860  0.019991              0.037165   \n",
            "1          -0.147943 -0.005011 -0.017633              0.033871   \n",
            "2           0.194019  0.008079  0.028344              0.041640   \n",
            "3          -0.010905 -0.000388 -0.001313              0.035575   \n",
            "4           0.161301  0.006069  0.020587              0.037623   \n",
            "\n",
            "   operating_cash_flow_to_total_debt  close         PE  revenue_growth  \\\n",
            "0                           0.024136  80.88  70.947368       -0.025233   \n",
            "1                           0.027435  79.89  73.972222       -0.088754   \n",
            "2                           0.052274  88.56  47.358289        0.239808   \n",
            "3                           0.032750  91.56  88.893204       -0.140455   \n",
            "4                           0.031931  96.53  76.611111        0.064566   \n",
            "\n",
            "   earnings_growth    return ticker  \n",
            "0         0.391691 -0.113255    DUK  \n",
            "1        -1.855011 -0.012240    DUK  \n",
            "2        -2.625935  0.108524    DUK  \n",
            "3        -1.048313  0.033875    DUK  \n",
            "4       -16.746032  0.054281    DUK  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the training dataset of the data before 2024, and others 2 quarters as testing\n",
        "train_df = combined_df[combined_df['date'] < '2024-01-01']\n",
        "test_df = combined_df[combined_df['date'] >= '2024-01-01']"
      ],
      "metadata": {
        "id": "bFBFFvgoygWN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "train_df.drop(columns = ['date', 'ticker', 'close'], inplace = True)\n",
        "test_df.drop(columns = ['date', 'ticker', 'close'], inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z8OTFzc7yphz",
        "outputId": "1259a2d2-d1de-483b-f680-8d7a8e0a6ce1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-fb2704bb9abe>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df.drop(columns = ['date', 'ticker', 'close'], inplace = True)\n",
            "<ipython-input-29-fb2704bb9abe>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df.drop(columns = ['date', 'ticker', 'close'], inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wFlRD9JiyvVc",
        "outputId": "56960d44-6412-4754-97e5-28d12857c362"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5957 entries, 0 to 7401\n",
            "Data columns (total 16 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   freeCashFlow                       5957 non-null   float64\n",
            " 1   current_ratio                      5946 non-null   float64\n",
            " 2   quick_ratio                        5946 non-null   float64\n",
            " 3   debt_to_equity                     5946 non-null   float64\n",
            " 4   interest_coverage_ratio            5947 non-null   float64\n",
            " 5   gross_profit_margin                5947 non-null   float64\n",
            " 6   operating_income_margin            5947 non-null   float64\n",
            " 7   net_profit_margin                  5947 non-null   float64\n",
            " 8   ROA                                5949 non-null   float64\n",
            " 9   ROE                                5949 non-null   float64\n",
            " 10  asset_turnover_ratio               5949 non-null   float64\n",
            " 11  operating_cash_flow_to_total_debt  5946 non-null   float64\n",
            " 12  PE                                 5957 non-null   float64\n",
            " 13  revenue_growth                     5957 non-null   float64\n",
            " 14  earnings_growth                    5957 non-null   float64\n",
            " 15  return                             5957 non-null   float64\n",
            "dtypes: float64(16)\n",
            "memory usage: 791.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace infinite values with NaN\n",
        "train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
        "test_df = test_df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Fill NaN values using interpolation, and fallback to column mean if still NaN\n",
        "train_df = train_df.interpolate(method='linear', axis=0).fillna(train_df.mean())\n",
        "test_df = test_df.interpolate(method='linear', axis=0).fillna(test_df.mean())"
      ],
      "metadata": {
        "id": "5zw3tomUywzZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Data\n",
        "\n",
        "## Define Target and Features: Separate features (e.g., financial indicators) from the target variable (e.g., returns).\n",
        "## Train-Test Split: Split data into a training set and a test set. Since this is a time series or financial data, use chronological split (e.g., all data before 2024 as training, 2024 data as testing) to avoid data leakage."
      ],
      "metadata": {
        "id": "2Yk6q9Oz0Vqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data and the return column is our target column\n",
        "X_train = train_df.drop(columns=['return'])\n",
        "y_train = train_df['return']\n",
        "X_test = test_df.drop(columns=['return'])\n",
        "y_test = test_df['return']"
      ],
      "metadata": {
        "id": "TqT7HMSzzoxj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling\n",
        "\n",
        "## Initialize Scalers: Use MinMaxScaler or StandardScaler to scale features and target variable separately.\n",
        "## Fit on Training Data: Fit the scaler on the training data and transform both the training and test data. This ensures that the test data does not influence the scaling parameters.\n",
        "## Scale the Target Variable: Scale the target variable (y) separately, since it needs to be scaled back later for real predictions."
      ],
      "metadata": {
        "id": "uykhiQz-0lYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the scaler\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler only on the training data and transform both train and test data\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)"
      ],
      "metadata": {
        "id": "FMYd1eX00r5f"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert scaled data back to DataFrame to maintain feature names (optional, but helpful for tracking features)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n"
      ],
      "metadata": {
        "id": "QkSNIjpn3nWA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape y to 2D for scaling, then scale\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n"
      ],
      "metadata": {
        "id": "rFHHlTxk3tc8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to numpy arrays (TabNet works with numpy arrays)\n",
        "X_train_np = X_train_scaled.values\n",
        "X_test_np = X_test_scaled.values\n"
      ],
      "metadata": {
        "id": "bObAjJpM37jk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence Generation for Time Series (Optional)\n",
        "\n",
        "## Create Sequences: If your model needs sequential data (like an LSTM), generate sequences by transforming each feature into a series of values over a chosen window (e.g., quarterly).\n",
        "## Define X and y: For sequence models, make sure that both features (X) and target (y) align in terms of sequence format."
      ],
      "metadata": {
        "id": "HE6fasNc0yuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps = 1  # Number of quarters in each sequence (you can change this)\n",
        "n_features = X_train_scaled.shape[1]  # Number of features in the dataset\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "# Function to create sequences and labels\n",
        "def create_sequences(data, n_timesteps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_timesteps -1):\n",
        "        X.append(data[i:i + n_timesteps, :-1])  # All features except target\n",
        "        y.append(data[i + n_timesteps + 1, -1])  # Target variable (e.g., return)\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "C4R91TWW01Hs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "train_df_scaled = scaler.fit_transform(train_df)\n",
        "test_df_scaled = scaler.transform(test_df)"
      ],
      "metadata": {
        "id": "_LEiGyVaRw5g"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training and testing sequences\n",
        "X_train, y_train = create_sequences(train_df_scaled, n_timesteps)\n",
        "X_test, y_test = create_sequences(test_df_scaled, n_timesteps)"
      ],
      "metadata": {
        "id": "VuS461PWNcOi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup with TabNet\n",
        "\n",
        "## Initialize TabNet Regressor: Set up the TabNet model with appropriate hyperparameters.\n",
        "## Train the Model: Train the model on the training dataset using X_train and y_train."
      ],
      "metadata": {
        "id": "UkyBFqJp03c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KbSYLih9AWb",
        "outputId": "39c2ff0f-3819-4fc3-f26c-65431bb2d465"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.66.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TabNet Regressor\n",
        "tabnet_model = TabNetRegressor()\n",
        "\n",
        "\n",
        "# Train the model\n",
        "tabnet_model.fit(\n",
        "    X_train=X_train_np,\n",
        "    y_train=y_train_scaled,\n",
        "    eval_set=[(X_test_np, y_test_scaled)],\n",
        "    eval_metric=['mae', 'rmse', 'mse'],          # We can also use MAE, MSE, etc.\n",
        "    max_epochs=1000,\n",
        "    patience = 500, # Stop if no improvement after 20 epochs\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=64,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ESVZyIw4059c",
        "outputId": "bc2a467f-8e19-43ca-ee75-18a883b8110e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.76108 | val_0_mae: 0.12512 | val_0_rmse: 0.14671 | val_0_mse: 0.02152 |  0:00:01s\n",
            "epoch 1  | loss: 0.08957 | val_0_mae: 0.06759 | val_0_rmse: 0.09258 | val_0_mse: 0.00857 |  0:00:02s\n",
            "epoch 2  | loss: 0.02455 | val_0_mae: 0.06191 | val_0_rmse: 0.08656 | val_0_mse: 0.00749 |  0:00:03s\n",
            "epoch 3  | loss: 0.01527 | val_0_mae: 0.07872 | val_0_rmse: 0.10367 | val_0_mse: 0.01075 |  0:00:04s\n",
            "epoch 4  | loss: 0.01312 | val_0_mae: 0.05913 | val_0_rmse: 0.08315 | val_0_mse: 0.00691 |  0:00:04s\n",
            "epoch 5  | loss: 0.01117 | val_0_mae: 0.05979 | val_0_rmse: 0.0832  | val_0_mse: 0.00692 |  0:00:05s\n",
            "epoch 6  | loss: 0.01111 | val_0_mae: 0.06383 | val_0_rmse: 0.08672 | val_0_mse: 0.00752 |  0:00:06s\n",
            "epoch 7  | loss: 0.01113 | val_0_mae: 0.05909 | val_0_rmse: 0.08317 | val_0_mse: 0.00692 |  0:00:07s\n",
            "epoch 8  | loss: 0.01093 | val_0_mae: 0.05911 | val_0_rmse: 0.0829  | val_0_mse: 0.00687 |  0:00:08s\n",
            "epoch 9  | loss: 0.01046 | val_0_mae: 0.05919 | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:00:08s\n",
            "epoch 10 | loss: 0.01058 | val_0_mae: 0.06392 | val_0_rmse: 0.08763 | val_0_mse: 0.00768 |  0:00:09s\n",
            "epoch 11 | loss: 0.01069 | val_0_mae: 0.05961 | val_0_rmse: 0.08435 | val_0_mse: 0.00712 |  0:00:10s\n",
            "epoch 12 | loss: 0.01071 | val_0_mae: 0.06444 | val_0_rmse: 0.09008 | val_0_mse: 0.00812 |  0:00:11s\n",
            "epoch 13 | loss: 0.01104 | val_0_mae: 0.06407 | val_0_rmse: 0.08943 | val_0_mse: 0.008   |  0:00:11s\n",
            "epoch 14 | loss: 0.01065 | val_0_mae: 0.06069 | val_0_rmse: 0.08571 | val_0_mse: 0.00735 |  0:00:12s\n",
            "epoch 15 | loss: 0.01034 | val_0_mae: 0.06233 | val_0_rmse: 0.08542 | val_0_mse: 0.0073  |  0:00:14s\n",
            "epoch 16 | loss: 0.01018 | val_0_mae: 0.06092 | val_0_rmse: 0.08411 | val_0_mse: 0.00707 |  0:00:15s\n",
            "epoch 17 | loss: 0.01043 | val_0_mae: 0.06112 | val_0_rmse: 0.08445 | val_0_mse: 0.00713 |  0:00:16s\n",
            "epoch 18 | loss: 0.01045 | val_0_mae: 0.05995 | val_0_rmse: 0.0837  | val_0_mse: 0.00701 |  0:00:17s\n",
            "epoch 19 | loss: 0.01003 | val_0_mae: 0.05905 | val_0_rmse: 0.08298 | val_0_mse: 0.00689 |  0:00:17s\n",
            "epoch 20 | loss: 0.01053 | val_0_mae: 0.06791 | val_0_rmse: 0.09088 | val_0_mse: 0.00826 |  0:00:18s\n",
            "epoch 21 | loss: 0.0107  | val_0_mae: 0.05967 | val_0_rmse: 0.08325 | val_0_mse: 0.00693 |  0:00:19s\n",
            "epoch 22 | loss: 0.01    | val_0_mae: 0.06056 | val_0_rmse: 0.09636 | val_0_mse: 0.00929 |  0:00:20s\n",
            "epoch 23 | loss: 0.01023 | val_0_mae: 0.05995 | val_0_rmse: 0.08845 | val_0_mse: 0.00782 |  0:00:21s\n",
            "epoch 24 | loss: 0.01006 | val_0_mae: 0.06073 | val_0_rmse: 0.10011 | val_0_mse: 0.01002 |  0:00:21s\n",
            "epoch 25 | loss: 0.00988 | val_0_mae: 0.06083 | val_0_rmse: 0.09532 | val_0_mse: 0.00909 |  0:00:22s\n",
            "epoch 26 | loss: 0.0099  | val_0_mae: 0.05911 | val_0_rmse: 0.08349 | val_0_mse: 0.00697 |  0:00:23s\n",
            "epoch 27 | loss: 0.00982 | val_0_mae: 0.05903 | val_0_rmse: 0.08294 | val_0_mse: 0.00688 |  0:00:24s\n",
            "epoch 28 | loss: 0.01009 | val_0_mae: 0.061   | val_0_rmse: 0.08443 | val_0_mse: 0.00713 |  0:00:24s\n",
            "epoch 29 | loss: 0.00973 | val_0_mae: 0.05907 | val_0_rmse: 0.08322 | val_0_mse: 0.00693 |  0:00:25s\n",
            "epoch 30 | loss: 0.00981 | val_0_mae: 0.05925 | val_0_rmse: 0.08312 | val_0_mse: 0.00691 |  0:00:26s\n",
            "epoch 31 | loss: 0.01    | val_0_mae: 0.07701 | val_0_rmse: 0.36647 | val_0_mse: 0.1343  |  0:00:27s\n",
            "epoch 32 | loss: 0.01002 | val_0_mae: 0.06015 | val_0_rmse: 0.08714 | val_0_mse: 0.00759 |  0:00:28s\n",
            "epoch 33 | loss: 0.00981 | val_0_mae: 0.05886 | val_0_rmse: 0.0828  | val_0_mse: 0.00686 |  0:00:29s\n",
            "epoch 34 | loss: 0.00987 | val_0_mae: 0.06051 | val_0_rmse: 0.10225 | val_0_mse: 0.01045 |  0:00:30s\n",
            "epoch 35 | loss: 0.00979 | val_0_mae: 0.05905 | val_0_rmse: 0.08284 | val_0_mse: 0.00686 |  0:00:31s\n",
            "epoch 36 | loss: 0.00995 | val_0_mae: 0.0597  | val_0_rmse: 0.08424 | val_0_mse: 0.0071  |  0:00:32s\n",
            "epoch 37 | loss: 0.00989 | val_0_mae: 0.05906 | val_0_rmse: 0.08418 | val_0_mse: 0.00709 |  0:00:33s\n",
            "epoch 38 | loss: 0.00987 | val_0_mae: 0.05981 | val_0_rmse: 0.08473 | val_0_mse: 0.00718 |  0:00:33s\n",
            "epoch 39 | loss: 0.00967 | val_0_mae: 0.05928 | val_0_rmse: 0.08406 | val_0_mse: 0.00707 |  0:00:34s\n",
            "epoch 40 | loss: 0.00966 | val_0_mae: 0.0592  | val_0_rmse: 0.08366 | val_0_mse: 0.007   |  0:00:35s\n",
            "epoch 41 | loss: 0.00981 | val_0_mae: 0.06107 | val_0_rmse: 0.08478 | val_0_mse: 0.00719 |  0:00:36s\n",
            "epoch 42 | loss: 0.00981 | val_0_mae: 0.05918 | val_0_rmse: 0.08345 | val_0_mse: 0.00696 |  0:00:37s\n",
            "epoch 43 | loss: 0.00988 | val_0_mae: 0.05903 | val_0_rmse: 0.08273 | val_0_mse: 0.00684 |  0:00:37s\n",
            "epoch 44 | loss: 0.00984 | val_0_mae: 0.05876 | val_0_rmse: 0.08324 | val_0_mse: 0.00693 |  0:00:38s\n",
            "epoch 45 | loss: 0.00976 | val_0_mae: 0.05853 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:00:39s\n",
            "epoch 46 | loss: 0.00983 | val_0_mae: 0.05978 | val_0_rmse: 0.08318 | val_0_mse: 0.00692 |  0:00:40s\n",
            "epoch 47 | loss: 0.00966 | val_0_mae: 0.05828 | val_0_rmse: 0.08217 | val_0_mse: 0.00675 |  0:00:41s\n",
            "epoch 48 | loss: 0.00969 | val_0_mae: 0.05978 | val_0_rmse: 0.08445 | val_0_mse: 0.00713 |  0:00:42s\n",
            "epoch 49 | loss: 0.00979 | val_0_mae: 0.05947 | val_0_rmse: 0.08292 | val_0_mse: 0.00688 |  0:00:43s\n",
            "epoch 50 | loss: 0.00976 | val_0_mae: 0.05911 | val_0_rmse: 0.08325 | val_0_mse: 0.00693 |  0:00:44s\n",
            "epoch 51 | loss: 0.00945 | val_0_mae: 0.06208 | val_0_rmse: 0.08527 | val_0_mse: 0.00727 |  0:00:45s\n",
            "epoch 52 | loss: 0.00956 | val_0_mae: 0.06065 | val_0_rmse: 0.08507 | val_0_mse: 0.00724 |  0:00:46s\n",
            "epoch 53 | loss: 0.00968 | val_0_mae: 0.06175 | val_0_rmse: 0.08675 | val_0_mse: 0.00753 |  0:00:47s\n",
            "epoch 54 | loss: 0.00974 | val_0_mae: 0.05961 | val_0_rmse: 0.08341 | val_0_mse: 0.00696 |  0:00:47s\n",
            "epoch 55 | loss: 0.00941 | val_0_mae: 0.05896 | val_0_rmse: 0.08309 | val_0_mse: 0.0069  |  0:00:48s\n",
            "epoch 56 | loss: 0.00972 | val_0_mae: 0.06123 | val_0_rmse: 0.08449 | val_0_mse: 0.00714 |  0:00:49s\n",
            "epoch 57 | loss: 0.00948 | val_0_mae: 0.06021 | val_0_rmse: 0.0927  | val_0_mse: 0.00859 |  0:00:50s\n",
            "epoch 58 | loss: 0.00953 | val_0_mae: 0.06165 | val_0_rmse: 0.08598 | val_0_mse: 0.00739 |  0:00:50s\n",
            "epoch 59 | loss: 0.00952 | val_0_mae: 0.05946 | val_0_rmse: 0.0855  | val_0_mse: 0.00731 |  0:00:51s\n",
            "epoch 60 | loss: 0.00951 | val_0_mae: 0.05897 | val_0_rmse: 0.08369 | val_0_mse: 0.007   |  0:00:52s\n",
            "epoch 61 | loss: 0.00944 | val_0_mae: 0.05887 | val_0_rmse: 0.08342 | val_0_mse: 0.00696 |  0:00:53s\n",
            "epoch 62 | loss: 0.00939 | val_0_mae: 0.05951 | val_0_rmse: 0.08503 | val_0_mse: 0.00723 |  0:00:54s\n",
            "epoch 63 | loss: 0.00973 | val_0_mae: 0.05887 | val_0_rmse: 0.08373 | val_0_mse: 0.00701 |  0:00:55s\n",
            "epoch 64 | loss: 0.00964 | val_0_mae: 0.05893 | val_0_rmse: 0.08346 | val_0_mse: 0.00697 |  0:00:56s\n",
            "epoch 65 | loss: 0.00992 | val_0_mae: 0.06549 | val_0_rmse: 0.08879 | val_0_mse: 0.00788 |  0:00:57s\n",
            "epoch 66 | loss: 0.00993 | val_0_mae: 0.05877 | val_0_rmse: 0.08293 | val_0_mse: 0.00688 |  0:00:58s\n",
            "epoch 67 | loss: 0.0095  | val_0_mae: 0.06125 | val_0_rmse: 0.08473 | val_0_mse: 0.00718 |  0:00:59s\n",
            "epoch 68 | loss: 0.00941 | val_0_mae: 0.06028 | val_0_rmse: 0.0849  | val_0_mse: 0.00721 |  0:01:00s\n",
            "epoch 69 | loss: 0.00949 | val_0_mae: 0.06024 | val_0_rmse: 0.10396 | val_0_mse: 0.01081 |  0:01:00s\n",
            "epoch 70 | loss: 0.00931 | val_0_mae: 0.06101 | val_0_rmse: 0.11935 | val_0_mse: 0.01424 |  0:01:01s\n",
            "epoch 71 | loss: 0.00942 | val_0_mae: 0.05956 | val_0_rmse: 0.08695 | val_0_mse: 0.00756 |  0:01:02s\n",
            "epoch 72 | loss: 0.00949 | val_0_mae: 0.06109 | val_0_rmse: 0.08874 | val_0_mse: 0.00788 |  0:01:03s\n",
            "epoch 73 | loss: 0.00953 | val_0_mae: 0.05888 | val_0_rmse: 0.08322 | val_0_mse: 0.00692 |  0:01:03s\n",
            "epoch 74 | loss: 0.00954 | val_0_mae: 0.06121 | val_0_rmse: 0.08963 | val_0_mse: 0.00803 |  0:01:04s\n",
            "epoch 75 | loss: 0.00956 | val_0_mae: 0.06054 | val_0_rmse: 0.08859 | val_0_mse: 0.00785 |  0:01:05s\n",
            "epoch 76 | loss: 0.00958 | val_0_mae: 0.06122 | val_0_rmse: 0.0859  | val_0_mse: 0.00738 |  0:01:06s\n",
            "epoch 77 | loss: 0.00935 | val_0_mae: 0.05913 | val_0_rmse: 0.08412 | val_0_mse: 0.00708 |  0:01:07s\n",
            "epoch 78 | loss: 0.00934 | val_0_mae: 0.0593  | val_0_rmse: 0.08589 | val_0_mse: 0.00738 |  0:01:08s\n",
            "epoch 79 | loss: 0.00924 | val_0_mae: 0.06657 | val_0_rmse: 0.09095 | val_0_mse: 0.00827 |  0:01:09s\n",
            "epoch 80 | loss: 0.00972 | val_0_mae: 0.05959 | val_0_rmse: 0.08424 | val_0_mse: 0.0071  |  0:01:10s\n",
            "epoch 81 | loss: 0.00954 | val_0_mae: 0.05973 | val_0_rmse: 0.08509 | val_0_mse: 0.00724 |  0:01:11s\n",
            "epoch 82 | loss: 0.00965 | val_0_mae: 0.0642  | val_0_rmse: 0.08839 | val_0_mse: 0.00781 |  0:01:12s\n",
            "epoch 83 | loss: 0.00948 | val_0_mae: 0.05995 | val_0_rmse: 0.08641 | val_0_mse: 0.00747 |  0:01:13s\n",
            "epoch 84 | loss: 0.00958 | val_0_mae: 0.05932 | val_0_rmse: 0.08444 | val_0_mse: 0.00713 |  0:01:13s\n",
            "epoch 85 | loss: 0.00938 | val_0_mae: 0.05897 | val_0_rmse: 0.08339 | val_0_mse: 0.00695 |  0:01:14s\n",
            "epoch 86 | loss: 0.0095  | val_0_mae: 0.06486 | val_0_rmse: 0.08898 | val_0_mse: 0.00792 |  0:01:15s\n",
            "epoch 87 | loss: 0.0093  | val_0_mae: 0.06189 | val_0_rmse: 0.08536 | val_0_mse: 0.00729 |  0:01:16s\n",
            "epoch 88 | loss: 0.0092  | val_0_mae: 0.05884 | val_0_rmse: 0.08281 | val_0_mse: 0.00686 |  0:01:16s\n",
            "epoch 89 | loss: 0.00935 | val_0_mae: 0.0587  | val_0_rmse: 0.08263 | val_0_mse: 0.00683 |  0:01:17s\n",
            "epoch 90 | loss: 0.00938 | val_0_mae: 0.0589  | val_0_rmse: 0.08283 | val_0_mse: 0.00686 |  0:01:18s\n",
            "epoch 91 | loss: 0.00934 | val_0_mae: 0.05988 | val_0_rmse: 0.08303 | val_0_mse: 0.00689 |  0:01:19s\n",
            "epoch 92 | loss: 0.0092  | val_0_mae: 0.05969 | val_0_rmse: 0.08315 | val_0_mse: 0.00691 |  0:01:20s\n",
            "epoch 93 | loss: 0.00927 | val_0_mae: 0.0588  | val_0_rmse: 0.08235 | val_0_mse: 0.00678 |  0:01:20s\n",
            "epoch 94 | loss: 0.00911 | val_0_mae: 0.05892 | val_0_rmse: 0.08314 | val_0_mse: 0.00691 |  0:01:21s\n",
            "epoch 95 | loss: 0.00943 | val_0_mae: 0.05858 | val_0_rmse: 0.08225 | val_0_mse: 0.00676 |  0:01:23s\n",
            "epoch 96 | loss: 0.00937 | val_0_mae: 0.05848 | val_0_rmse: 0.08208 | val_0_mse: 0.00674 |  0:01:24s\n",
            "epoch 97 | loss: 0.00922 | val_0_mae: 0.05994 | val_0_rmse: 0.0837  | val_0_mse: 0.00701 |  0:01:25s\n",
            "epoch 98 | loss: 0.00919 | val_0_mae: 0.0592  | val_0_rmse: 0.08306 | val_0_mse: 0.0069  |  0:01:26s\n",
            "epoch 99 | loss: 0.0092  | val_0_mae: 0.06058 | val_0_rmse: 0.08416 | val_0_mse: 0.00708 |  0:01:26s\n",
            "epoch 100| loss: 0.00926 | val_0_mae: 0.0599  | val_0_rmse: 0.08302 | val_0_mse: 0.00689 |  0:01:27s\n",
            "epoch 101| loss: 0.00907 | val_0_mae: 0.06291 | val_0_rmse: 0.08606 | val_0_mse: 0.00741 |  0:01:28s\n",
            "epoch 102| loss: 0.00922 | val_0_mae: 0.06008 | val_0_rmse: 0.08375 | val_0_mse: 0.00701 |  0:01:29s\n",
            "epoch 103| loss: 0.00917 | val_0_mae: 0.06395 | val_0_rmse: 0.08719 | val_0_mse: 0.0076  |  0:01:29s\n",
            "epoch 104| loss: 0.00932 | val_0_mae: 0.06174 | val_0_rmse: 0.08538 | val_0_mse: 0.00729 |  0:01:30s\n",
            "epoch 105| loss: 0.0092  | val_0_mae: 0.05974 | val_0_rmse: 0.08365 | val_0_mse: 0.007   |  0:01:31s\n",
            "epoch 106| loss: 0.00912 | val_0_mae: 0.06194 | val_0_rmse: 0.08564 | val_0_mse: 0.00733 |  0:01:32s\n",
            "epoch 107| loss: 0.00911 | val_0_mae: 0.06186 | val_0_rmse: 0.08571 | val_0_mse: 0.00735 |  0:01:33s\n",
            "epoch 108| loss: 0.00906 | val_0_mae: 0.06137 | val_0_rmse: 0.08509 | val_0_mse: 0.00724 |  0:01:33s\n",
            "epoch 109| loss: 0.00895 | val_0_mae: 0.0608  | val_0_rmse: 0.0841  | val_0_mse: 0.00707 |  0:01:34s\n",
            "epoch 110| loss: 0.00924 | val_0_mae: 0.05939 | val_0_rmse: 0.08414 | val_0_mse: 0.00708 |  0:01:35s\n",
            "epoch 111| loss: 0.00908 | val_0_mae: 0.05978 | val_0_rmse: 0.0912  | val_0_mse: 0.00832 |  0:01:36s\n",
            "epoch 112| loss: 0.00923 | val_0_mae: 0.06245 | val_0_rmse: 0.09561 | val_0_mse: 0.00914 |  0:01:38s\n",
            "epoch 113| loss: 0.00911 | val_0_mae: 0.06214 | val_0_rmse: 0.09418 | val_0_mse: 0.00887 |  0:01:39s\n",
            "epoch 114| loss: 0.00904 | val_0_mae: 0.06274 | val_0_rmse: 0.09567 | val_0_mse: 0.00915 |  0:01:40s\n",
            "epoch 115| loss: 0.00907 | val_0_mae: 0.06134 | val_0_rmse: 0.09326 | val_0_mse: 0.0087  |  0:01:41s\n",
            "epoch 116| loss: 0.00906 | val_0_mae: 0.0613  | val_0_rmse: 0.10141 | val_0_mse: 0.01028 |  0:01:41s\n",
            "epoch 117| loss: 0.00911 | val_0_mae: 0.06541 | val_0_rmse: 0.08857 | val_0_mse: 0.00784 |  0:01:42s\n",
            "epoch 118| loss: 0.00909 | val_0_mae: 0.06284 | val_0_rmse: 0.08585 | val_0_mse: 0.00737 |  0:01:43s\n",
            "epoch 119| loss: 0.00908 | val_0_mae: 0.06011 | val_0_rmse: 0.08348 | val_0_mse: 0.00697 |  0:01:44s\n",
            "epoch 120| loss: 0.00905 | val_0_mae: 0.06037 | val_0_rmse: 0.08729 | val_0_mse: 0.00762 |  0:01:44s\n",
            "epoch 121| loss: 0.00907 | val_0_mae: 0.06329 | val_0_rmse: 0.08998 | val_0_mse: 0.0081  |  0:01:45s\n",
            "epoch 122| loss: 0.00923 | val_0_mae: 0.06257 | val_0_rmse: 0.08559 | val_0_mse: 0.00732 |  0:01:46s\n",
            "epoch 123| loss: 0.00904 | val_0_mae: 0.0604  | val_0_rmse: 0.08373 | val_0_mse: 0.00701 |  0:01:47s\n",
            "epoch 124| loss: 0.00905 | val_0_mae: 0.06027 | val_0_rmse: 0.0836  | val_0_mse: 0.00699 |  0:01:48s\n",
            "epoch 125| loss: 0.00901 | val_0_mae: 0.05914 | val_0_rmse: 0.08299 | val_0_mse: 0.00689 |  0:01:48s\n",
            "epoch 126| loss: 0.00895 | val_0_mae: 0.06199 | val_0_rmse: 0.08495 | val_0_mse: 0.00722 |  0:01:50s\n",
            "epoch 127| loss: 0.00904 | val_0_mae: 0.05889 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:01:51s\n",
            "epoch 128| loss: 0.00904 | val_0_mae: 0.05956 | val_0_rmse: 0.08302 | val_0_mse: 0.00689 |  0:01:52s\n",
            "epoch 129| loss: 0.00925 | val_0_mae: 0.06163 | val_0_rmse: 0.08529 | val_0_mse: 0.00727 |  0:01:53s\n",
            "epoch 130| loss: 0.00903 | val_0_mae: 0.05993 | val_0_rmse: 0.08362 | val_0_mse: 0.00699 |  0:01:54s\n",
            "epoch 131| loss: 0.00915 | val_0_mae: 0.05942 | val_0_rmse: 0.083   | val_0_mse: 0.00689 |  0:01:55s\n",
            "epoch 132| loss: 0.00918 | val_0_mae: 0.06043 | val_0_rmse: 0.08371 | val_0_mse: 0.00701 |  0:01:56s\n",
            "epoch 133| loss: 0.00912 | val_0_mae: 0.06372 | val_0_rmse: 0.08659 | val_0_mse: 0.0075  |  0:01:57s\n",
            "epoch 134| loss: 0.00908 | val_0_mae: 0.06258 | val_0_rmse: 0.08614 | val_0_mse: 0.00742 |  0:01:58s\n",
            "epoch 135| loss: 0.00917 | val_0_mae: 0.06314 | val_0_rmse: 0.0875  | val_0_mse: 0.00766 |  0:01:58s\n",
            "epoch 136| loss: 0.00892 | val_0_mae: 0.06824 | val_0_rmse: 0.09138 | val_0_mse: 0.00835 |  0:01:59s\n",
            "epoch 137| loss: 0.00913 | val_0_mae: 0.06549 | val_0_rmse: 0.08837 | val_0_mse: 0.00781 |  0:02:00s\n",
            "epoch 138| loss: 0.00895 | val_0_mae: 0.061   | val_0_rmse: 0.08413 | val_0_mse: 0.00708 |  0:02:01s\n",
            "epoch 139| loss: 0.00899 | val_0_mae: 0.06002 | val_0_rmse: 0.08327 | val_0_mse: 0.00693 |  0:02:01s\n",
            "epoch 140| loss: 0.009   | val_0_mae: 0.0628  | val_0_rmse: 0.08585 | val_0_mse: 0.00737 |  0:02:02s\n",
            "epoch 141| loss: 0.00919 | val_0_mae: 0.06503 | val_0_rmse: 0.08787 | val_0_mse: 0.00772 |  0:02:03s\n",
            "epoch 142| loss: 0.00904 | val_0_mae: 0.05996 | val_0_rmse: 0.08332 | val_0_mse: 0.00694 |  0:02:05s\n",
            "epoch 143| loss: 0.00917 | val_0_mae: 0.0591  | val_0_rmse: 0.08254 | val_0_mse: 0.00681 |  0:02:06s\n",
            "epoch 144| loss: 0.0093  | val_0_mae: 0.05957 | val_0_rmse: 0.08333 | val_0_mse: 0.00694 |  0:02:06s\n",
            "epoch 145| loss: 0.00921 | val_0_mae: 0.06    | val_0_rmse: 0.08331 | val_0_mse: 0.00694 |  0:02:07s\n",
            "epoch 146| loss: 0.00893 | val_0_mae: 0.05976 | val_0_rmse: 0.08327 | val_0_mse: 0.00693 |  0:02:08s\n",
            "epoch 147| loss: 0.00896 | val_0_mae: 0.06692 | val_0_rmse: 0.09063 | val_0_mse: 0.00821 |  0:02:09s\n",
            "epoch 148| loss: 0.00907 | val_0_mae: 0.06369 | val_0_rmse: 0.08689 | val_0_mse: 0.00755 |  0:02:10s\n",
            "epoch 149| loss: 0.0092  | val_0_mae: 0.06356 | val_0_rmse: 0.08659 | val_0_mse: 0.0075  |  0:02:10s\n",
            "epoch 150| loss: 0.00918 | val_0_mae: 0.06459 | val_0_rmse: 0.08747 | val_0_mse: 0.00765 |  0:02:11s\n",
            "epoch 151| loss: 0.00922 | val_0_mae: 0.0627  | val_0_rmse: 0.08569 | val_0_mse: 0.00734 |  0:02:12s\n",
            "epoch 152| loss: 0.00913 | val_0_mae: 0.06012 | val_0_rmse: 0.08334 | val_0_mse: 0.00695 |  0:02:13s\n",
            "epoch 153| loss: 0.00919 | val_0_mae: 0.05897 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:02:13s\n",
            "epoch 154| loss: 0.00944 | val_0_mae: 0.0589  | val_0_rmse: 0.0826  | val_0_mse: 0.00682 |  0:02:14s\n",
            "epoch 155| loss: 0.00938 | val_0_mae: 0.06397 | val_0_rmse: 0.08691 | val_0_mse: 0.00755 |  0:02:15s\n",
            "epoch 156| loss: 0.00913 | val_0_mae: 0.06303 | val_0_rmse: 0.086   | val_0_mse: 0.0074  |  0:02:16s\n",
            "epoch 157| loss: 0.009   | val_0_mae: 0.06091 | val_0_rmse: 0.08407 | val_0_mse: 0.00707 |  0:02:17s\n",
            "epoch 158| loss: 0.00902 | val_0_mae: 0.06154 | val_0_rmse: 0.0854  | val_0_mse: 0.00729 |  0:02:18s\n",
            "epoch 159| loss: 0.00904 | val_0_mae: 0.0593  | val_0_rmse: 0.08362 | val_0_mse: 0.00699 |  0:02:19s\n",
            "epoch 160| loss: 0.00916 | val_0_mae: 0.06039 | val_0_rmse: 0.08376 | val_0_mse: 0.00702 |  0:02:20s\n",
            "epoch 161| loss: 0.00905 | val_0_mae: 0.06482 | val_0_rmse: 0.0881  | val_0_mse: 0.00776 |  0:02:21s\n",
            "epoch 162| loss: 0.00946 | val_0_mae: 0.06017 | val_0_rmse: 0.08365 | val_0_mse: 0.007   |  0:02:22s\n",
            "epoch 163| loss: 0.00913 | val_0_mae: 0.06347 | val_0_rmse: 0.08671 | val_0_mse: 0.00752 |  0:02:22s\n",
            "epoch 164| loss: 0.00909 | val_0_mae: 0.06193 | val_0_rmse: 0.08509 | val_0_mse: 0.00724 |  0:02:23s\n",
            "epoch 165| loss: 0.00916 | val_0_mae: 0.05913 | val_0_rmse: 0.08326 | val_0_mse: 0.00693 |  0:02:24s\n",
            "epoch 166| loss: 0.00912 | val_0_mae: 0.06107 | val_0_rmse: 0.08493 | val_0_mse: 0.00721 |  0:02:25s\n",
            "epoch 167| loss: 0.0091  | val_0_mae: 0.06067 | val_0_rmse: 0.08419 | val_0_mse: 0.00709 |  0:02:25s\n",
            "epoch 168| loss: 0.00905 | val_0_mae: 0.05891 | val_0_rmse: 0.08295 | val_0_mse: 0.00688 |  0:02:26s\n",
            "epoch 169| loss: 0.0092  | val_0_mae: 0.05945 | val_0_rmse: 0.08348 | val_0_mse: 0.00697 |  0:02:27s\n",
            "epoch 170| loss: 0.00906 | val_0_mae: 0.06242 | val_0_rmse: 0.08618 | val_0_mse: 0.00743 |  0:02:28s\n",
            "epoch 171| loss: 0.00912 | val_0_mae: 0.06021 | val_0_rmse: 0.0845  | val_0_mse: 0.00714 |  0:02:29s\n",
            "epoch 172| loss: 0.00901 | val_0_mae: 0.06153 | val_0_rmse: 0.08657 | val_0_mse: 0.00749 |  0:02:29s\n",
            "epoch 173| loss: 0.00908 | val_0_mae: 0.06156 | val_0_rmse: 0.08617 | val_0_mse: 0.00743 |  0:02:30s\n",
            "epoch 174| loss: 0.00915 | val_0_mae: 0.06918 | val_0_rmse: 0.09437 | val_0_mse: 0.00891 |  0:02:32s\n",
            "epoch 175| loss: 0.00924 | val_0_mae: 0.06172 | val_0_rmse: 0.08543 | val_0_mse: 0.0073  |  0:02:33s\n",
            "epoch 176| loss: 0.00929 | val_0_mae: 0.0621  | val_0_rmse: 0.08597 | val_0_mse: 0.00739 |  0:02:34s\n",
            "epoch 177| loss: 0.00914 | val_0_mae: 0.06111 | val_0_rmse: 0.08561 | val_0_mse: 0.00733 |  0:02:34s\n",
            "epoch 178| loss: 0.00897 | val_0_mae: 0.06117 | val_0_rmse: 0.0849  | val_0_mse: 0.00721 |  0:02:35s\n",
            "epoch 179| loss: 0.00901 | val_0_mae: 0.06108 | val_0_rmse: 0.08554 | val_0_mse: 0.00732 |  0:02:36s\n",
            "epoch 180| loss: 0.00911 | val_0_mae: 0.06121 | val_0_rmse: 0.08575 | val_0_mse: 0.00735 |  0:02:37s\n",
            "epoch 181| loss: 0.00905 | val_0_mae: 0.05978 | val_0_rmse: 0.08419 | val_0_mse: 0.00709 |  0:02:38s\n",
            "epoch 182| loss: 0.00905 | val_0_mae: 0.061   | val_0_rmse: 0.08473 | val_0_mse: 0.00718 |  0:02:38s\n",
            "epoch 183| loss: 0.0092  | val_0_mae: 0.06028 | val_0_rmse: 0.08408 | val_0_mse: 0.00707 |  0:02:39s\n",
            "epoch 184| loss: 0.00904 | val_0_mae: 0.05974 | val_0_rmse: 0.08403 | val_0_mse: 0.00706 |  0:02:40s\n",
            "epoch 185| loss: 0.00918 | val_0_mae: 0.06069 | val_0_rmse: 0.08492 | val_0_mse: 0.00721 |  0:02:41s\n",
            "epoch 186| loss: 0.00898 | val_0_mae: 0.06112 | val_0_rmse: 0.08591 | val_0_mse: 0.00738 |  0:02:42s\n",
            "epoch 187| loss: 0.00906 | val_0_mae: 0.06221 | val_0_rmse: 0.08624 | val_0_mse: 0.00744 |  0:02:42s\n",
            "epoch 188| loss: 0.00901 | val_0_mae: 0.06279 | val_0_rmse: 0.08699 | val_0_mse: 0.00757 |  0:02:43s\n",
            "epoch 189| loss: 0.00903 | val_0_mae: 0.06731 | val_0_rmse: 0.09186 | val_0_mse: 0.00844 |  0:02:44s\n",
            "epoch 190| loss: 0.00911 | val_0_mae: 0.06203 | val_0_rmse: 0.08569 | val_0_mse: 0.00734 |  0:02:45s\n",
            "epoch 191| loss: 0.00905 | val_0_mae: 0.06156 | val_0_rmse: 0.08468 | val_0_mse: 0.00717 |  0:02:47s\n",
            "epoch 192| loss: 0.00909 | val_0_mae: 0.06118 | val_0_rmse: 0.08439 | val_0_mse: 0.00712 |  0:02:47s\n",
            "epoch 193| loss: 0.00895 | val_0_mae: 0.05964 | val_0_rmse: 0.08372 | val_0_mse: 0.00701 |  0:02:48s\n",
            "epoch 194| loss: 0.00898 | val_0_mae: 0.06511 | val_0_rmse: 0.08809 | val_0_mse: 0.00776 |  0:02:49s\n",
            "epoch 195| loss: 0.00916 | val_0_mae: 0.0702  | val_0_rmse: 0.09352 | val_0_mse: 0.00875 |  0:02:50s\n",
            "epoch 196| loss: 0.0091  | val_0_mae: 0.06203 | val_0_rmse: 0.08495 | val_0_mse: 0.00722 |  0:02:50s\n",
            "epoch 197| loss: 0.00912 | val_0_mae: 0.05903 | val_0_rmse: 0.08272 | val_0_mse: 0.00684 |  0:02:51s\n",
            "epoch 198| loss: 0.00898 | val_0_mae: 0.06313 | val_0_rmse: 0.08597 | val_0_mse: 0.00739 |  0:02:52s\n",
            "epoch 199| loss: 0.00899 | val_0_mae: 0.05974 | val_0_rmse: 0.08311 | val_0_mse: 0.00691 |  0:02:53s\n",
            "epoch 200| loss: 0.00904 | val_0_mae: 0.06761 | val_0_rmse: 0.30851 | val_0_mse: 0.09518 |  0:02:54s\n",
            "epoch 201| loss: 0.00906 | val_0_mae: 0.07135 | val_0_rmse: 0.09399 | val_0_mse: 0.00883 |  0:02:54s\n",
            "epoch 202| loss: 0.00937 | val_0_mae: 0.06377 | val_0_rmse: 0.09531 | val_0_mse: 0.00908 |  0:02:55s\n",
            "epoch 203| loss: 0.00908 | val_0_mae: 0.06324 | val_0_rmse: 0.08762 | val_0_mse: 0.00768 |  0:02:56s\n",
            "epoch 204| loss: 0.00904 | val_0_mae: 0.06111 | val_0_rmse: 0.09804 | val_0_mse: 0.00961 |  0:02:57s\n",
            "epoch 205| loss: 0.00897 | val_0_mae: 0.06313 | val_0_rmse: 0.08609 | val_0_mse: 0.00741 |  0:02:58s\n",
            "epoch 206| loss: 0.00906 | val_0_mae: 0.06447 | val_0_rmse: 0.0878  | val_0_mse: 0.00771 |  0:02:59s\n",
            "epoch 207| loss: 0.00902 | val_0_mae: 0.06165 | val_0_rmse: 0.08476 | val_0_mse: 0.00718 |  0:03:00s\n",
            "epoch 208| loss: 0.00884 | val_0_mae: 0.06165 | val_0_rmse: 0.08464 | val_0_mse: 0.00716 |  0:03:01s\n",
            "epoch 209| loss: 0.00898 | val_0_mae: 0.05914 | val_0_rmse: 0.08533 | val_0_mse: 0.00728 |  0:03:02s\n",
            "epoch 210| loss: 0.00897 | val_0_mae: 0.0622  | val_0_rmse: 0.13321 | val_0_mse: 0.01774 |  0:03:03s\n",
            "epoch 211| loss: 0.00904 | val_0_mae: 0.06876 | val_0_rmse: 0.10809 | val_0_mse: 0.01168 |  0:03:03s\n",
            "epoch 212| loss: 0.00901 | val_0_mae: 0.06882 | val_0_rmse: 0.25824 | val_0_mse: 0.06669 |  0:03:04s\n",
            "epoch 213| loss: 0.00907 | val_0_mae: 0.06295 | val_0_rmse: 0.10391 | val_0_mse: 0.0108  |  0:03:05s\n",
            "epoch 214| loss: 0.00899 | val_0_mae: 0.06403 | val_0_rmse: 0.08743 | val_0_mse: 0.00764 |  0:03:06s\n",
            "epoch 215| loss: 0.00894 | val_0_mae: 0.06226 | val_0_rmse: 0.08523 | val_0_mse: 0.00726 |  0:03:07s\n",
            "epoch 216| loss: 0.00893 | val_0_mae: 0.06092 | val_0_rmse: 0.08395 | val_0_mse: 0.00705 |  0:03:07s\n",
            "epoch 217| loss: 0.00895 | val_0_mae: 0.06154 | val_0_rmse: 0.08448 | val_0_mse: 0.00714 |  0:03:08s\n",
            "epoch 218| loss: 0.00892 | val_0_mae: 0.06083 | val_0_rmse: 0.08387 | val_0_mse: 0.00703 |  0:03:09s\n",
            "epoch 219| loss: 0.00891 | val_0_mae: 0.06292 | val_0_rmse: 0.08597 | val_0_mse: 0.00739 |  0:03:10s\n",
            "epoch 220| loss: 0.00901 | val_0_mae: 0.06055 | val_0_rmse: 0.08423 | val_0_mse: 0.00709 |  0:03:11s\n",
            "epoch 221| loss: 0.00923 | val_0_mae: 0.06461 | val_0_rmse: 0.08808 | val_0_mse: 0.00776 |  0:03:12s\n",
            "epoch 222| loss: 0.00929 | val_0_mae: 0.06573 | val_0_rmse: 0.1061  | val_0_mse: 0.01126 |  0:03:13s\n",
            "epoch 223| loss: 0.009   | val_0_mae: 0.06497 | val_0_rmse: 0.09664 | val_0_mse: 0.00934 |  0:03:14s\n",
            "epoch 224| loss: 0.00899 | val_0_mae: 0.05945 | val_0_rmse: 0.08329 | val_0_mse: 0.00694 |  0:03:15s\n",
            "epoch 225| loss: 0.00914 | val_0_mae: 0.06088 | val_0_rmse: 0.08439 | val_0_mse: 0.00712 |  0:03:16s\n",
            "epoch 226| loss: 0.00906 | val_0_mae: 0.0594  | val_0_rmse: 0.08721 | val_0_mse: 0.00761 |  0:03:16s\n",
            "epoch 227| loss: 0.00913 | val_0_mae: 0.06272 | val_0_rmse: 0.08587 | val_0_mse: 0.00737 |  0:03:17s\n",
            "epoch 228| loss: 0.00906 | val_0_mae: 0.0632  | val_0_rmse: 0.15826 | val_0_mse: 0.02505 |  0:03:18s\n",
            "epoch 229| loss: 0.00905 | val_0_mae: 0.05993 | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:03:19s\n",
            "epoch 230| loss: 0.0089  | val_0_mae: 0.05955 | val_0_rmse: 0.08316 | val_0_mse: 0.00691 |  0:03:20s\n",
            "epoch 231| loss: 0.00896 | val_0_mae: 0.06191 | val_0_rmse: 0.08892 | val_0_mse: 0.00791 |  0:03:20s\n",
            "epoch 232| loss: 0.00899 | val_0_mae: 0.07299 | val_0_rmse: 0.51933 | val_0_mse: 0.2697  |  0:03:21s\n",
            "epoch 233| loss: 0.0089  | val_0_mae: 0.07269 | val_0_rmse: 0.23372 | val_0_mse: 0.05463 |  0:03:22s\n",
            "epoch 234| loss: 0.0091  | val_0_mae: 0.0643  | val_0_rmse: 0.17953 | val_0_mse: 0.03223 |  0:03:23s\n",
            "epoch 235| loss: 0.00901 | val_0_mae: 0.06141 | val_0_rmse: 0.0845  | val_0_mse: 0.00714 |  0:03:23s\n",
            "epoch 236| loss: 0.00906 | val_0_mae: 0.0608  | val_0_rmse: 0.08391 | val_0_mse: 0.00704 |  0:03:24s\n",
            "epoch 237| loss: 0.00917 | val_0_mae: 0.06333 | val_0_rmse: 0.19889 | val_0_mse: 0.03956 |  0:03:25s\n",
            "epoch 238| loss: 0.00898 | val_0_mae: 0.06233 | val_0_rmse: 0.11533 | val_0_mse: 0.0133  |  0:03:27s\n",
            "epoch 239| loss: 0.00891 | val_0_mae: 0.0598  | val_0_rmse: 0.08399 | val_0_mse: 0.00705 |  0:03:28s\n",
            "epoch 240| loss: 0.00894 | val_0_mae: 0.06237 | val_0_rmse: 0.08522 | val_0_mse: 0.00726 |  0:03:29s\n",
            "epoch 241| loss: 0.00907 | val_0_mae: 0.05898 | val_0_rmse: 0.08261 | val_0_mse: 0.00683 |  0:03:29s\n",
            "epoch 242| loss: 0.00905 | val_0_mae: 0.05875 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:03:30s\n",
            "epoch 243| loss: 0.00904 | val_0_mae: 0.06219 | val_0_rmse: 0.08519 | val_0_mse: 0.00726 |  0:03:31s\n",
            "epoch 244| loss: 0.00902 | val_0_mae: 0.05845 | val_0_rmse: 0.08244 | val_0_mse: 0.0068  |  0:03:32s\n",
            "epoch 245| loss: 0.00899 | val_0_mae: 0.0601  | val_0_rmse: 0.08413 | val_0_mse: 0.00708 |  0:03:33s\n",
            "epoch 246| loss: 0.00897 | val_0_mae: 0.05865 | val_0_rmse: 0.08233 | val_0_mse: 0.00678 |  0:03:33s\n",
            "epoch 247| loss: 0.00895 | val_0_mae: 0.05939 | val_0_rmse: 0.0828  | val_0_mse: 0.00686 |  0:03:34s\n",
            "epoch 248| loss: 0.00898 | val_0_mae: 0.05902 | val_0_rmse: 0.08296 | val_0_mse: 0.00688 |  0:03:35s\n",
            "epoch 249| loss: 0.00895 | val_0_mae: 0.0642  | val_0_rmse: 0.08693 | val_0_mse: 0.00756 |  0:03:36s\n",
            "epoch 250| loss: 0.00898 | val_0_mae: 0.06272 | val_0_rmse: 0.08538 | val_0_mse: 0.00729 |  0:03:36s\n",
            "epoch 251| loss: 0.00901 | val_0_mae: 0.06232 | val_0_rmse: 0.08516 | val_0_mse: 0.00725 |  0:03:37s\n",
            "epoch 252| loss: 0.009   | val_0_mae: 0.06367 | val_0_rmse: 0.08648 | val_0_mse: 0.00748 |  0:03:38s\n",
            "epoch 253| loss: 0.00896 | val_0_mae: 0.064   | val_0_rmse: 0.08672 | val_0_mse: 0.00752 |  0:03:39s\n",
            "epoch 254| loss: 0.00902 | val_0_mae: 0.05871 | val_0_rmse: 0.0823  | val_0_mse: 0.00677 |  0:03:40s\n",
            "epoch 255| loss: 0.00884 | val_0_mae: 0.05903 | val_0_rmse: 0.08246 | val_0_mse: 0.0068  |  0:03:41s\n",
            "epoch 256| loss: 0.0088  | val_0_mae: 0.06246 | val_0_rmse: 0.08534 | val_0_mse: 0.00728 |  0:03:42s\n",
            "epoch 257| loss: 0.00891 | val_0_mae: 0.05908 | val_0_rmse: 0.08266 | val_0_mse: 0.00683 |  0:03:43s\n",
            "epoch 258| loss: 0.00894 | val_0_mae: 0.0596  | val_0_rmse: 0.08286 | val_0_mse: 0.00687 |  0:03:44s\n",
            "epoch 259| loss: 0.00893 | val_0_mae: 0.06039 | val_0_rmse: 0.08367 | val_0_mse: 0.007   |  0:03:45s\n",
            "epoch 260| loss: 0.00903 | val_0_mae: 0.05848 | val_0_rmse: 0.08211 | val_0_mse: 0.00674 |  0:03:46s\n",
            "epoch 261| loss: 0.00887 | val_0_mae: 0.0591  | val_0_rmse: 0.08236 | val_0_mse: 0.00678 |  0:03:46s\n",
            "epoch 262| loss: 0.00903 | val_0_mae: 0.05905 | val_0_rmse: 0.08243 | val_0_mse: 0.00679 |  0:03:47s\n",
            "epoch 263| loss: 0.0092  | val_0_mae: 0.05939 | val_0_rmse: 0.0833  | val_0_mse: 0.00694 |  0:03:48s\n",
            "epoch 264| loss: 0.00893 | val_0_mae: 0.0594  | val_0_rmse: 0.0829  | val_0_mse: 0.00687 |  0:03:49s\n",
            "epoch 265| loss: 0.00893 | val_0_mae: 0.0593  | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:03:49s\n",
            "epoch 266| loss: 0.00899 | val_0_mae: 0.05989 | val_0_rmse: 0.08327 | val_0_mse: 0.00693 |  0:03:50s\n",
            "epoch 267| loss: 0.00905 | val_0_mae: 0.05969 | val_0_rmse: 0.0837  | val_0_mse: 0.00701 |  0:03:51s\n",
            "epoch 268| loss: 0.00893 | val_0_mae: 0.06265 | val_0_rmse: 0.13911 | val_0_mse: 0.01935 |  0:03:52s\n",
            "epoch 269| loss: 0.00903 | val_0_mae: 0.05945 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:03:53s\n",
            "epoch 270| loss: 0.00915 | val_0_mae: 0.06432 | val_0_rmse: 0.08697 | val_0_mse: 0.00756 |  0:03:54s\n",
            "epoch 271| loss: 0.00904 | val_0_mae: 0.06435 | val_0_rmse: 0.08724 | val_0_mse: 0.00761 |  0:03:55s\n",
            "epoch 272| loss: 0.00898 | val_0_mae: 0.05899 | val_0_rmse: 0.08271 | val_0_mse: 0.00684 |  0:03:56s\n",
            "epoch 273| loss: 0.00892 | val_0_mae: 0.05888 | val_0_rmse: 0.08274 | val_0_mse: 0.00685 |  0:03:57s\n",
            "epoch 274| loss: 0.00898 | val_0_mae: 0.06822 | val_0_rmse: 0.09392 | val_0_mse: 0.00882 |  0:03:58s\n",
            "epoch 275| loss: 0.00903 | val_0_mae: 0.06284 | val_0_rmse: 0.08618 | val_0_mse: 0.00743 |  0:03:58s\n",
            "epoch 276| loss: 0.00899 | val_0_mae: 0.06515 | val_0_rmse: 0.08821 | val_0_mse: 0.00778 |  0:03:59s\n",
            "epoch 277| loss: 0.0089  | val_0_mae: 0.06449 | val_0_rmse: 0.08773 | val_0_mse: 0.0077  |  0:04:00s\n",
            "epoch 278| loss: 0.00892 | val_0_mae: 0.05962 | val_0_rmse: 0.08462 | val_0_mse: 0.00716 |  0:04:01s\n",
            "epoch 279| loss: 0.00894 | val_0_mae: 0.06491 | val_0_rmse: 0.08853 | val_0_mse: 0.00784 |  0:04:02s\n",
            "epoch 280| loss: 0.00896 | val_0_mae: 0.05904 | val_0_rmse: 0.08296 | val_0_mse: 0.00688 |  0:04:02s\n",
            "epoch 281| loss: 0.00893 | val_0_mae: 0.06045 | val_0_rmse: 0.0862  | val_0_mse: 0.00743 |  0:04:03s\n",
            "epoch 282| loss: 0.00909 | val_0_mae: 0.06167 | val_0_rmse: 0.08471 | val_0_mse: 0.00718 |  0:04:04s\n",
            "epoch 283| loss: 0.0092  | val_0_mae: 0.06216 | val_0_rmse: 0.08511 | val_0_mse: 0.00724 |  0:04:05s\n",
            "epoch 284| loss: 0.00912 | val_0_mae: 0.05896 | val_0_rmse: 0.08273 | val_0_mse: 0.00684 |  0:04:06s\n",
            "epoch 285| loss: 0.009   | val_0_mae: 0.06399 | val_0_rmse: 0.08704 | val_0_mse: 0.00758 |  0:04:07s\n",
            "epoch 286| loss: 0.00898 | val_0_mae: 0.06033 | val_0_rmse: 0.08384 | val_0_mse: 0.00703 |  0:04:08s\n",
            "epoch 287| loss: 0.00904 | val_0_mae: 0.0614  | val_0_rmse: 0.08465 | val_0_mse: 0.00717 |  0:04:09s\n",
            "epoch 288| loss: 0.00911 | val_0_mae: 0.06038 | val_0_rmse: 0.08843 | val_0_mse: 0.00782 |  0:04:10s\n",
            "epoch 289| loss: 0.00912 | val_0_mae: 0.06311 | val_0_rmse: 0.08604 | val_0_mse: 0.0074  |  0:04:11s\n",
            "epoch 290| loss: 0.00915 | val_0_mae: 0.06008 | val_0_rmse: 0.08355 | val_0_mse: 0.00698 |  0:04:12s\n",
            "epoch 291| loss: 0.00894 | val_0_mae: 0.05918 | val_0_rmse: 0.08289 | val_0_mse: 0.00687 |  0:04:12s\n",
            "epoch 292| loss: 0.00894 | val_0_mae: 0.06376 | val_0_rmse: 0.08673 | val_0_mse: 0.00752 |  0:04:13s\n",
            "epoch 293| loss: 0.00912 | val_0_mae: 0.05902 | val_0_rmse: 0.08316 | val_0_mse: 0.00692 |  0:04:14s\n",
            "epoch 294| loss: 0.00901 | val_0_mae: 0.05886 | val_0_rmse: 0.08254 | val_0_mse: 0.00681 |  0:04:15s\n",
            "epoch 295| loss: 0.00899 | val_0_mae: 0.05903 | val_0_rmse: 0.08296 | val_0_mse: 0.00688 |  0:04:15s\n",
            "epoch 296| loss: 0.00894 | val_0_mae: 0.05865 | val_0_rmse: 0.08238 | val_0_mse: 0.00679 |  0:04:16s\n",
            "epoch 297| loss: 0.00901 | val_0_mae: 0.06515 | val_0_rmse: 0.08817 | val_0_mse: 0.00777 |  0:04:17s\n",
            "epoch 298| loss: 0.00937 | val_0_mae: 0.05912 | val_0_rmse: 0.08304 | val_0_mse: 0.0069  |  0:04:18s\n",
            "epoch 299| loss: 0.00912 | val_0_mae: 0.06023 | val_0_rmse: 0.08396 | val_0_mse: 0.00705 |  0:04:19s\n",
            "epoch 300| loss: 0.00901 | val_0_mae: 0.06069 | val_0_rmse: 0.08428 | val_0_mse: 0.0071  |  0:04:19s\n",
            "epoch 301| loss: 0.00899 | val_0_mae: 0.06157 | val_0_rmse: 0.10253 | val_0_mse: 0.01051 |  0:04:20s\n",
            "epoch 302| loss: 0.00905 | val_0_mae: 0.06041 | val_0_rmse: 0.08973 | val_0_mse: 0.00805 |  0:04:22s\n",
            "epoch 303| loss: 0.00886 | val_0_mae: 0.06108 | val_0_rmse: 0.10159 | val_0_mse: 0.01032 |  0:04:23s\n",
            "epoch 304| loss: 0.0091  | val_0_mae: 0.06049 | val_0_rmse: 0.08959 | val_0_mse: 0.00803 |  0:04:24s\n",
            "epoch 305| loss: 0.00906 | val_0_mae: 0.06067 | val_0_rmse: 0.09299 | val_0_mse: 0.00865 |  0:04:24s\n",
            "epoch 306| loss: 0.00883 | val_0_mae: 0.06828 | val_0_rmse: 0.10456 | val_0_mse: 0.01093 |  0:04:25s\n",
            "epoch 307| loss: 0.00894 | val_0_mae: 0.06134 | val_0_rmse: 0.09368 | val_0_mse: 0.00878 |  0:04:26s\n",
            "epoch 308| loss: 0.0089  | val_0_mae: 0.06087 | val_0_rmse: 0.10039 | val_0_mse: 0.01008 |  0:04:27s\n",
            "epoch 309| loss: 0.00896 | val_0_mae: 0.07339 | val_0_rmse: 0.39401 | val_0_mse: 0.15525 |  0:04:27s\n",
            "epoch 310| loss: 0.00897 | val_0_mae: 0.0621  | val_0_rmse: 0.08648 | val_0_mse: 0.00748 |  0:04:28s\n",
            "epoch 311| loss: 0.009   | val_0_mae: 0.06159 | val_0_rmse: 0.09731 | val_0_mse: 0.00947 |  0:04:29s\n",
            "epoch 312| loss: 0.009   | val_0_mae: 0.06445 | val_0_rmse: 0.17935 | val_0_mse: 0.03216 |  0:04:30s\n",
            "epoch 313| loss: 0.00901 | val_0_mae: 0.0663  | val_0_rmse: 0.10917 | val_0_mse: 0.01192 |  0:04:31s\n",
            "epoch 314| loss: 0.00893 | val_0_mae: 0.06268 | val_0_rmse: 0.17436 | val_0_mse: 0.0304  |  0:04:31s\n",
            "epoch 315| loss: 0.00893 | val_0_mae: 0.05865 | val_0_rmse: 0.08235 | val_0_mse: 0.00678 |  0:04:32s\n",
            "epoch 316| loss: 0.00886 | val_0_mae: 0.05899 | val_0_rmse: 0.08251 | val_0_mse: 0.00681 |  0:04:33s\n",
            "epoch 317| loss: 0.00896 | val_0_mae: 0.06725 | val_0_rmse: 0.09952 | val_0_mse: 0.0099  |  0:04:34s\n",
            "epoch 318| loss: 0.00902 | val_0_mae: 0.05886 | val_0_rmse: 0.08274 | val_0_mse: 0.00685 |  0:04:35s\n",
            "epoch 319| loss: 0.00887 | val_0_mae: 0.05872 | val_0_rmse: 0.08245 | val_0_mse: 0.0068  |  0:04:37s\n",
            "epoch 320| loss: 0.00901 | val_0_mae: 0.06187 | val_0_rmse: 0.08496 | val_0_mse: 0.00722 |  0:04:37s\n",
            "epoch 321| loss: 0.00903 | val_0_mae: 0.0619  | val_0_rmse: 0.08496 | val_0_mse: 0.00722 |  0:04:38s\n",
            "epoch 322| loss: 0.00901 | val_0_mae: 0.05882 | val_0_rmse: 0.08271 | val_0_mse: 0.00684 |  0:04:39s\n",
            "epoch 323| loss: 0.00899 | val_0_mae: 0.05965 | val_0_rmse: 0.08389 | val_0_mse: 0.00704 |  0:04:40s\n",
            "epoch 324| loss: 0.00895 | val_0_mae: 0.06034 | val_0_rmse: 0.08371 | val_0_mse: 0.00701 |  0:04:41s\n",
            "epoch 325| loss: 0.00911 | val_0_mae: 0.05985 | val_0_rmse: 0.0833  | val_0_mse: 0.00694 |  0:04:41s\n",
            "epoch 326| loss: 0.00896 | val_0_mae: 0.05989 | val_0_rmse: 0.08353 | val_0_mse: 0.00698 |  0:04:42s\n",
            "epoch 327| loss: 0.00896 | val_0_mae: 0.05907 | val_0_rmse: 0.08274 | val_0_mse: 0.00685 |  0:04:43s\n",
            "epoch 328| loss: 0.00903 | val_0_mae: 0.06412 | val_0_rmse: 0.08699 | val_0_mse: 0.00757 |  0:04:44s\n",
            "epoch 329| loss: 0.00898 | val_0_mae: 0.06042 | val_0_rmse: 0.08397 | val_0_mse: 0.00705 |  0:04:44s\n",
            "epoch 330| loss: 0.00885 | val_0_mae: 0.0596  | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:04:45s\n",
            "epoch 331| loss: 0.00898 | val_0_mae: 0.05993 | val_0_rmse: 0.08368 | val_0_mse: 0.007   |  0:04:46s\n",
            "epoch 332| loss: 0.00897 | val_0_mae: 0.0586  | val_0_rmse: 0.08233 | val_0_mse: 0.00678 |  0:04:47s\n",
            "epoch 333| loss: 0.00902 | val_0_mae: 0.05938 | val_0_rmse: 0.08277 | val_0_mse: 0.00685 |  0:04:48s\n",
            "epoch 334| loss: 0.00898 | val_0_mae: 0.06107 | val_0_rmse: 0.0842  | val_0_mse: 0.00709 |  0:04:49s\n",
            "epoch 335| loss: 0.00903 | val_0_mae: 0.0593  | val_0_rmse: 0.08281 | val_0_mse: 0.00686 |  0:04:50s\n",
            "epoch 336| loss: 0.00886 | val_0_mae: 0.05878 | val_0_rmse: 0.08232 | val_0_mse: 0.00678 |  0:04:51s\n",
            "epoch 337| loss: 0.00891 | val_0_mae: 0.05924 | val_0_rmse: 0.0833  | val_0_mse: 0.00694 |  0:04:52s\n",
            "epoch 338| loss: 0.00893 | val_0_mae: 0.06274 | val_0_rmse: 0.0858  | val_0_mse: 0.00736 |  0:04:52s\n",
            "epoch 339| loss: 0.00894 | val_0_mae: 0.05993 | val_0_rmse: 0.08397 | val_0_mse: 0.00705 |  0:04:53s\n",
            "epoch 340| loss: 0.00909 | val_0_mae: 0.05881 | val_0_rmse: 0.08272 | val_0_mse: 0.00684 |  0:04:54s\n",
            "epoch 341| loss: 0.00887 | val_0_mae: 0.0591  | val_0_rmse: 0.08262 | val_0_mse: 0.00683 |  0:04:55s\n",
            "epoch 342| loss: 0.00897 | val_0_mae: 0.05869 | val_0_rmse: 0.08231 | val_0_mse: 0.00678 |  0:04:56s\n",
            "epoch 343| loss: 0.00897 | val_0_mae: 0.05893 | val_0_rmse: 0.0829  | val_0_mse: 0.00687 |  0:04:56s\n",
            "epoch 344| loss: 0.00894 | val_0_mae: 0.05902 | val_0_rmse: 0.08278 | val_0_mse: 0.00685 |  0:04:57s\n",
            "epoch 345| loss: 0.00887 | val_0_mae: 0.05945 | val_0_rmse: 0.08297 | val_0_mse: 0.00688 |  0:04:58s\n",
            "epoch 346| loss: 0.00887 | val_0_mae: 0.06309 | val_0_rmse: 0.0862  | val_0_mse: 0.00743 |  0:04:59s\n",
            "epoch 347| loss: 0.00917 | val_0_mae: 0.0614  | val_0_rmse: 0.08473 | val_0_mse: 0.00718 |  0:04:59s\n",
            "epoch 348| loss: 0.00903 | val_0_mae: 0.05921 | val_0_rmse: 0.08335 | val_0_mse: 0.00695 |  0:05:00s\n",
            "epoch 349| loss: 0.00903 | val_0_mae: 0.06049 | val_0_rmse: 0.08409 | val_0_mse: 0.00707 |  0:05:01s\n",
            "epoch 350| loss: 0.00907 | val_0_mae: 0.05952 | val_0_rmse: 0.08313 | val_0_mse: 0.00691 |  0:05:02s\n",
            "epoch 351| loss: 0.00903 | val_0_mae: 0.05919 | val_0_rmse: 0.08317 | val_0_mse: 0.00692 |  0:05:04s\n",
            "epoch 352| loss: 0.0089  | val_0_mae: 0.05878 | val_0_rmse: 0.0827  | val_0_mse: 0.00684 |  0:05:05s\n",
            "epoch 353| loss: 0.00892 | val_0_mae: 0.06126 | val_0_rmse: 0.08451 | val_0_mse: 0.00714 |  0:05:05s\n",
            "epoch 354| loss: 0.00896 | val_0_mae: 0.06118 | val_0_rmse: 0.08438 | val_0_mse: 0.00712 |  0:05:06s\n",
            "epoch 355| loss: 0.00894 | val_0_mae: 0.06705 | val_0_rmse: 0.18355 | val_0_mse: 0.03369 |  0:05:07s\n",
            "epoch 356| loss: 0.00895 | val_0_mae: 0.07059 | val_0_rmse: 0.22508 | val_0_mse: 0.05066 |  0:05:08s\n",
            "epoch 357| loss: 0.009   | val_0_mae: 0.06249 | val_0_rmse: 0.13093 | val_0_mse: 0.01714 |  0:05:09s\n",
            "epoch 358| loss: 0.00896 | val_0_mae: 0.06316 | val_0_rmse: 0.10626 | val_0_mse: 0.01129 |  0:05:10s\n",
            "epoch 359| loss: 0.00902 | val_0_mae: 0.06328 | val_0_rmse: 0.15323 | val_0_mse: 0.02348 |  0:05:11s\n",
            "epoch 360| loss: 0.0089  | val_0_mae: 0.0716  | val_0_rmse: 0.49571 | val_0_mse: 0.24573 |  0:05:11s\n",
            "epoch 361| loss: 0.00893 | val_0_mae: 0.0719  | val_0_rmse: 0.43411 | val_0_mse: 0.18845 |  0:05:12s\n",
            "epoch 362| loss: 0.00894 | val_0_mae: 0.06165 | val_0_rmse: 0.12869 | val_0_mse: 0.01656 |  0:05:13s\n",
            "epoch 363| loss: 0.00898 | val_0_mae: 0.06432 | val_0_rmse: 0.08727 | val_0_mse: 0.00762 |  0:05:15s\n",
            "epoch 364| loss: 0.00902 | val_0_mae: 0.06562 | val_0_rmse: 0.25259 | val_0_mse: 0.0638  |  0:05:17s\n",
            "epoch 365| loss: 0.00913 | val_0_mae: 0.05963 | val_0_rmse: 0.08343 | val_0_mse: 0.00696 |  0:05:18s\n",
            "epoch 366| loss: 0.00904 | val_0_mae: 0.07026 | val_0_rmse: 0.26055 | val_0_mse: 0.06788 |  0:05:20s\n",
            "epoch 367| loss: 0.00905 | val_0_mae: 0.06993 | val_0_rmse: 0.32204 | val_0_mse: 0.10371 |  0:05:21s\n",
            "epoch 368| loss: 0.0091  | val_0_mae: 0.07333 | val_0_rmse: 0.45533 | val_0_mse: 0.20733 |  0:05:22s\n",
            "epoch 369| loss: 0.00901 | val_0_mae: 0.06158 | val_0_rmse: 0.10536 | val_0_mse: 0.0111  |  0:05:24s\n",
            "epoch 370| loss: 0.00906 | val_0_mae: 0.06678 | val_0_rmse: 0.09214 | val_0_mse: 0.00849 |  0:05:24s\n",
            "epoch 371| loss: 0.00915 | val_0_mae: 0.06585 | val_0_rmse: 0.13334 | val_0_mse: 0.01778 |  0:05:25s\n",
            "epoch 372| loss: 0.00897 | val_0_mae: 0.06594 | val_0_rmse: 0.15111 | val_0_mse: 0.02283 |  0:05:26s\n",
            "epoch 373| loss: 0.00892 | val_0_mae: 0.06868 | val_0_rmse: 0.25225 | val_0_mse: 0.06363 |  0:05:27s\n",
            "epoch 374| loss: 0.00902 | val_0_mae: 0.06882 | val_0_rmse: 0.31208 | val_0_mse: 0.09739 |  0:05:28s\n",
            "epoch 375| loss: 0.00894 | val_0_mae: 0.07111 | val_0_rmse: 0.29961 | val_0_mse: 0.08976 |  0:05:30s\n",
            "epoch 376| loss: 0.00933 | val_0_mae: 0.0631  | val_0_rmse: 0.14563 | val_0_mse: 0.02121 |  0:05:32s\n",
            "epoch 377| loss: 0.00907 | val_0_mae: 0.06048 | val_0_rmse: 0.10055 | val_0_mse: 0.01011 |  0:05:32s\n",
            "epoch 378| loss: 0.00902 | val_0_mae: 0.06805 | val_0_rmse: 0.31229 | val_0_mse: 0.09752 |  0:05:33s\n",
            "epoch 379| loss: 0.00886 | val_0_mae: 0.06275 | val_0_rmse: 0.15169 | val_0_mse: 0.02301 |  0:05:34s\n",
            "epoch 380| loss: 0.00893 | val_0_mae: 0.06261 | val_0_rmse: 0.11277 | val_0_mse: 0.01272 |  0:05:35s\n",
            "epoch 381| loss: 0.00895 | val_0_mae: 0.06025 | val_0_rmse: 0.08648 | val_0_mse: 0.00748 |  0:05:36s\n",
            "epoch 382| loss: 0.00898 | val_0_mae: 0.06136 | val_0_rmse: 0.08736 | val_0_mse: 0.00763 |  0:05:37s\n",
            "epoch 383| loss: 0.009   | val_0_mae: 0.06019 | val_0_rmse: 0.08391 | val_0_mse: 0.00704 |  0:05:38s\n",
            "epoch 384| loss: 0.00896 | val_0_mae: 0.06311 | val_0_rmse: 0.08782 | val_0_mse: 0.00771 |  0:05:39s\n",
            "epoch 385| loss: 0.00903 | val_0_mae: 0.06156 | val_0_rmse: 0.09003 | val_0_mse: 0.00811 |  0:05:40s\n",
            "epoch 386| loss: 0.00901 | val_0_mae: 0.06125 | val_0_rmse: 0.10077 | val_0_mse: 0.01015 |  0:05:41s\n",
            "epoch 387| loss: 0.00896 | val_0_mae: 0.06443 | val_0_rmse: 0.10251 | val_0_mse: 0.01051 |  0:05:42s\n",
            "epoch 388| loss: 0.00899 | val_0_mae: 0.06478 | val_0_rmse: 0.15528 | val_0_mse: 0.02411 |  0:05:43s\n",
            "epoch 389| loss: 0.0089  | val_0_mae: 0.05938 | val_0_rmse: 0.08772 | val_0_mse: 0.00769 |  0:05:46s\n",
            "epoch 390| loss: 0.00903 | val_0_mae: 0.06698 | val_0_rmse: 0.0952  | val_0_mse: 0.00906 |  0:05:47s\n",
            "epoch 391| loss: 0.00905 | val_0_mae: 0.0606  | val_0_rmse: 0.09024 | val_0_mse: 0.00814 |  0:05:48s\n",
            "epoch 392| loss: 0.00888 | val_0_mae: 0.06148 | val_0_rmse: 0.08798 | val_0_mse: 0.00774 |  0:05:49s\n",
            "epoch 393| loss: 0.00899 | val_0_mae: 0.06086 | val_0_rmse: 0.08526 | val_0_mse: 0.00727 |  0:05:50s\n",
            "epoch 394| loss: 0.00893 | val_0_mae: 0.06018 | val_0_rmse: 0.08639 | val_0_mse: 0.00746 |  0:05:52s\n",
            "epoch 395| loss: 0.00904 | val_0_mae: 0.0621  | val_0_rmse: 0.08735 | val_0_mse: 0.00763 |  0:05:52s\n",
            "epoch 396| loss: 0.00894 | val_0_mae: 0.05984 | val_0_rmse: 0.08419 | val_0_mse: 0.00709 |  0:05:53s\n",
            "epoch 397| loss: 0.00892 | val_0_mae: 0.06076 | val_0_rmse: 0.08421 | val_0_mse: 0.00709 |  0:05:54s\n",
            "epoch 398| loss: 0.00889 | val_0_mae: 0.06655 | val_0_rmse: 0.08928 | val_0_mse: 0.00797 |  0:05:55s\n",
            "epoch 399| loss: 0.00895 | val_0_mae: 0.05901 | val_0_rmse: 0.08389 | val_0_mse: 0.00704 |  0:05:57s\n",
            "epoch 400| loss: 0.00893 | val_0_mae: 0.05914 | val_0_rmse: 0.08243 | val_0_mse: 0.00679 |  0:05:58s\n",
            "epoch 401| loss: 0.00899 | val_0_mae: 0.05913 | val_0_rmse: 0.08309 | val_0_mse: 0.0069  |  0:05:59s\n",
            "epoch 402| loss: 0.00899 | val_0_mae: 0.06059 | val_0_rmse: 0.08385 | val_0_mse: 0.00703 |  0:06:00s\n",
            "epoch 403| loss: 0.00899 | val_0_mae: 0.06007 | val_0_rmse: 0.08402 | val_0_mse: 0.00706 |  0:06:01s\n",
            "epoch 404| loss: 0.00901 | val_0_mae: 0.05962 | val_0_rmse: 0.08324 | val_0_mse: 0.00693 |  0:06:02s\n",
            "epoch 405| loss: 0.00896 | val_0_mae: 0.05971 | val_0_rmse: 0.08375 | val_0_mse: 0.00701 |  0:06:03s\n",
            "epoch 406| loss: 0.00899 | val_0_mae: 0.05943 | val_0_rmse: 0.08346 | val_0_mse: 0.00697 |  0:06:03s\n",
            "epoch 407| loss: 0.00898 | val_0_mae: 0.05923 | val_0_rmse: 0.08329 | val_0_mse: 0.00694 |  0:06:04s\n",
            "epoch 408| loss: 0.00904 | val_0_mae: 0.06535 | val_0_rmse: 0.08869 | val_0_mse: 0.00787 |  0:06:05s\n",
            "epoch 409| loss: 0.00906 | val_0_mae: 0.05927 | val_0_rmse: 0.08351 | val_0_mse: 0.00697 |  0:06:06s\n",
            "epoch 410| loss: 0.00899 | val_0_mae: 0.05901 | val_0_rmse: 0.08303 | val_0_mse: 0.00689 |  0:06:07s\n",
            "epoch 411| loss: 0.00906 | val_0_mae: 0.06407 | val_0_rmse: 0.08785 | val_0_mse: 0.00772 |  0:06:08s\n",
            "epoch 412| loss: 0.00896 | val_0_mae: 0.06535 | val_0_rmse: 0.08823 | val_0_mse: 0.00778 |  0:06:09s\n",
            "epoch 413| loss: 0.00901 | val_0_mae: 0.05897 | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:06:10s\n",
            "epoch 414| loss: 0.00905 | val_0_mae: 0.06254 | val_0_rmse: 0.08603 | val_0_mse: 0.0074  |  0:06:11s\n",
            "epoch 415| loss: 0.00894 | val_0_mae: 0.06181 | val_0_rmse: 0.08526 | val_0_mse: 0.00727 |  0:06:12s\n",
            "epoch 416| loss: 0.00895 | val_0_mae: 0.06687 | val_0_rmse: 0.09004 | val_0_mse: 0.00811 |  0:06:14s\n",
            "epoch 417| loss: 0.00919 | val_0_mae: 0.06112 | val_0_rmse: 0.08461 | val_0_mse: 0.00716 |  0:06:15s\n",
            "epoch 418| loss: 0.00887 | val_0_mae: 0.06174 | val_0_rmse: 0.08549 | val_0_mse: 0.00731 |  0:06:16s\n",
            "epoch 419| loss: 0.00899 | val_0_mae: 0.06153 | val_0_rmse: 0.08498 | val_0_mse: 0.00722 |  0:06:16s\n",
            "epoch 420| loss: 0.00905 | val_0_mae: 0.06143 | val_0_rmse: 0.08431 | val_0_mse: 0.00711 |  0:06:17s\n",
            "epoch 421| loss: 0.00913 | val_0_mae: 0.0595  | val_0_rmse: 0.08337 | val_0_mse: 0.00695 |  0:06:18s\n",
            "epoch 422| loss: 0.00889 | val_0_mae: 0.06036 | val_0_rmse: 0.08407 | val_0_mse: 0.00707 |  0:06:19s\n",
            "epoch 423| loss: 0.00891 | val_0_mae: 0.06093 | val_0_rmse: 0.08452 | val_0_mse: 0.00714 |  0:06:19s\n",
            "epoch 424| loss: 0.00896 | val_0_mae: 0.06019 | val_0_rmse: 0.08394 | val_0_mse: 0.00705 |  0:06:20s\n",
            "epoch 425| loss: 0.00896 | val_0_mae: 0.05893 | val_0_rmse: 0.08358 | val_0_mse: 0.00699 |  0:06:21s\n",
            "epoch 426| loss: 0.00897 | val_0_mae: 0.06042 | val_0_rmse: 0.08491 | val_0_mse: 0.00721 |  0:06:22s\n",
            "epoch 427| loss: 0.00899 | val_0_mae: 0.063   | val_0_rmse: 0.08633 | val_0_mse: 0.00745 |  0:06:23s\n",
            "epoch 428| loss: 0.00926 | val_0_mae: 0.05986 | val_0_rmse: 0.08311 | val_0_mse: 0.00691 |  0:06:24s\n",
            "epoch 429| loss: 0.00899 | val_0_mae: 0.05871 | val_0_rmse: 0.08279 | val_0_mse: 0.00685 |  0:06:25s\n",
            "epoch 430| loss: 0.0089  | val_0_mae: 0.05992 | val_0_rmse: 0.08376 | val_0_mse: 0.00702 |  0:06:26s\n",
            "epoch 431| loss: 0.00898 | val_0_mae: 0.05951 | val_0_rmse: 0.08339 | val_0_mse: 0.00695 |  0:06:27s\n",
            "epoch 432| loss: 0.00895 | val_0_mae: 0.05914 | val_0_rmse: 0.08311 | val_0_mse: 0.00691 |  0:06:28s\n",
            "epoch 433| loss: 0.00886 | val_0_mae: 0.05886 | val_0_rmse: 0.08322 | val_0_mse: 0.00693 |  0:06:29s\n",
            "epoch 434| loss: 0.009   | val_0_mae: 0.06082 | val_0_rmse: 0.08448 | val_0_mse: 0.00714 |  0:06:30s\n",
            "epoch 435| loss: 0.00895 | val_0_mae: 0.05901 | val_0_rmse: 0.0835  | val_0_mse: 0.00697 |  0:06:30s\n",
            "epoch 436| loss: 0.00891 | val_0_mae: 0.05885 | val_0_rmse: 0.08329 | val_0_mse: 0.00694 |  0:06:32s\n",
            "epoch 437| loss: 0.00896 | val_0_mae: 0.06105 | val_0_rmse: 0.08466 | val_0_mse: 0.00717 |  0:06:33s\n",
            "epoch 438| loss: 0.00888 | val_0_mae: 0.06089 | val_0_rmse: 0.08459 | val_0_mse: 0.00716 |  0:06:35s\n",
            "epoch 439| loss: 0.00897 | val_0_mae: 0.06069 | val_0_rmse: 0.08677 | val_0_mse: 0.00753 |  0:06:35s\n",
            "epoch 440| loss: 0.00897 | val_0_mae: 0.05938 | val_0_rmse: 0.08781 | val_0_mse: 0.00771 |  0:06:36s\n",
            "epoch 441| loss: 0.00893 | val_0_mae: 0.06031 | val_0_rmse: 0.08945 | val_0_mse: 0.008   |  0:06:37s\n",
            "epoch 442| loss: 0.00898 | val_0_mae: 0.06238 | val_0_rmse: 0.09104 | val_0_mse: 0.00829 |  0:06:38s\n",
            "epoch 443| loss: 0.00888 | val_0_mae: 0.06319 | val_0_rmse: 0.08763 | val_0_mse: 0.00768 |  0:06:39s\n",
            "epoch 444| loss: 0.00895 | val_0_mae: 0.06002 | val_0_rmse: 0.08415 | val_0_mse: 0.00708 |  0:06:40s\n",
            "epoch 445| loss: 0.00891 | val_0_mae: 0.06152 | val_0_rmse: 0.085   | val_0_mse: 0.00722 |  0:06:41s\n",
            "epoch 446| loss: 0.00899 | val_0_mae: 0.05929 | val_0_rmse: 0.08572 | val_0_mse: 0.00735 |  0:06:42s\n",
            "epoch 447| loss: 0.00893 | val_0_mae: 0.06147 | val_0_rmse: 0.08787 | val_0_mse: 0.00772 |  0:06:43s\n",
            "epoch 448| loss: 0.00891 | val_0_mae: 0.06137 | val_0_rmse: 0.08751 | val_0_mse: 0.00766 |  0:06:44s\n",
            "epoch 449| loss: 0.00888 | val_0_mae: 0.06289 | val_0_rmse: 0.08868 | val_0_mse: 0.00786 |  0:06:45s\n",
            "epoch 450| loss: 0.00926 | val_0_mae: 0.05946 | val_0_rmse: 0.08508 | val_0_mse: 0.00724 |  0:06:46s\n",
            "epoch 451| loss: 0.00894 | val_0_mae: 0.06131 | val_0_rmse: 0.08722 | val_0_mse: 0.00761 |  0:06:47s\n",
            "epoch 452| loss: 0.00889 | val_0_mae: 0.05911 | val_0_rmse: 0.08489 | val_0_mse: 0.00721 |  0:06:48s\n",
            "epoch 453| loss: 0.00893 | val_0_mae: 0.05977 | val_0_rmse: 0.08524 | val_0_mse: 0.00727 |  0:06:49s\n",
            "epoch 454| loss: 0.00892 | val_0_mae: 0.06218 | val_0_rmse: 0.08678 | val_0_mse: 0.00753 |  0:06:49s\n",
            "epoch 455| loss: 0.00893 | val_0_mae: 0.06003 | val_0_rmse: 0.08499 | val_0_mse: 0.00722 |  0:06:50s\n",
            "epoch 456| loss: 0.00889 | val_0_mae: 0.05913 | val_0_rmse: 0.08409 | val_0_mse: 0.00707 |  0:06:51s\n",
            "epoch 457| loss: 0.00902 | val_0_mae: 0.06308 | val_0_rmse: 0.08785 | val_0_mse: 0.00772 |  0:06:54s\n",
            "epoch 458| loss: 0.00884 | val_0_mae: 0.06628 | val_0_rmse: 0.09219 | val_0_mse: 0.0085  |  0:06:56s\n",
            "epoch 459| loss: 0.00907 | val_0_mae: 0.05939 | val_0_rmse: 0.08707 | val_0_mse: 0.00758 |  0:06:57s\n",
            "epoch 460| loss: 0.00895 | val_0_mae: 0.05966 | val_0_rmse: 0.08576 | val_0_mse: 0.00735 |  0:06:57s\n",
            "epoch 461| loss: 0.00888 | val_0_mae: 0.05951 | val_0_rmse: 0.08599 | val_0_mse: 0.00739 |  0:06:58s\n",
            "epoch 462| loss: 0.00908 | val_0_mae: 0.05911 | val_0_rmse: 0.08475 | val_0_mse: 0.00718 |  0:06:59s\n",
            "epoch 463| loss: 0.00901 | val_0_mae: 0.0598  | val_0_rmse: 0.0836  | val_0_mse: 0.00699 |  0:07:00s\n",
            "epoch 464| loss: 0.00892 | val_0_mae: 0.0591  | val_0_rmse: 0.08302 | val_0_mse: 0.00689 |  0:07:02s\n",
            "epoch 465| loss: 0.00899 | val_0_mae: 0.05919 | val_0_rmse: 0.0839  | val_0_mse: 0.00704 |  0:07:03s\n",
            "epoch 466| loss: 0.00893 | val_0_mae: 0.05888 | val_0_rmse: 0.08418 | val_0_mse: 0.00709 |  0:07:04s\n",
            "epoch 467| loss: 0.00893 | val_0_mae: 0.05893 | val_0_rmse: 0.08309 | val_0_mse: 0.0069  |  0:07:05s\n",
            "epoch 468| loss: 0.00889 | val_0_mae: 0.05966 | val_0_rmse: 0.08288 | val_0_mse: 0.00687 |  0:07:06s\n",
            "epoch 469| loss: 0.00894 | val_0_mae: 0.0595  | val_0_rmse: 0.08339 | val_0_mse: 0.00695 |  0:07:07s\n",
            "epoch 470| loss: 0.00886 | val_0_mae: 0.05848 | val_0_rmse: 0.08266 | val_0_mse: 0.00683 |  0:07:08s\n",
            "epoch 471| loss: 0.0088  | val_0_mae: 0.05874 | val_0_rmse: 0.08304 | val_0_mse: 0.0069  |  0:07:09s\n",
            "epoch 472| loss: 0.00888 | val_0_mae: 0.06108 | val_0_rmse: 0.08459 | val_0_mse: 0.00715 |  0:07:10s\n",
            "epoch 473| loss: 0.00883 | val_0_mae: 0.06099 | val_0_rmse: 0.08401 | val_0_mse: 0.00706 |  0:07:11s\n",
            "epoch 474| loss: 0.00895 | val_0_mae: 0.05936 | val_0_rmse: 0.08368 | val_0_mse: 0.007   |  0:07:11s\n",
            "epoch 475| loss: 0.00915 | val_0_mae: 0.06178 | val_0_rmse: 0.08632 | val_0_mse: 0.00745 |  0:07:12s\n",
            "epoch 476| loss: 0.00922 | val_0_mae: 0.0588  | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:07:13s\n",
            "epoch 477| loss: 0.00904 | val_0_mae: 0.0614  | val_0_rmse: 0.08595 | val_0_mse: 0.00739 |  0:07:14s\n",
            "epoch 478| loss: 0.00888 | val_0_mae: 0.06179 | val_0_rmse: 0.08648 | val_0_mse: 0.00748 |  0:07:14s\n",
            "epoch 479| loss: 0.00889 | val_0_mae: 0.05882 | val_0_rmse: 0.08314 | val_0_mse: 0.00691 |  0:07:15s\n",
            "epoch 480| loss: 0.00885 | val_0_mae: 0.059   | val_0_rmse: 0.08341 | val_0_mse: 0.00696 |  0:07:16s\n",
            "epoch 481| loss: 0.00889 | val_0_mae: 0.05876 | val_0_rmse: 0.08306 | val_0_mse: 0.0069  |  0:07:17s\n",
            "epoch 482| loss: 0.00912 | val_0_mae: 0.05955 | val_0_rmse: 0.08335 | val_0_mse: 0.00695 |  0:07:18s\n",
            "epoch 483| loss: 0.0089  | val_0_mae: 0.05903 | val_0_rmse: 0.08345 | val_0_mse: 0.00696 |  0:07:18s\n",
            "epoch 484| loss: 0.00885 | val_0_mae: 0.06328 | val_0_rmse: 0.08807 | val_0_mse: 0.00776 |  0:07:19s\n",
            "epoch 485| loss: 0.00893 | val_0_mae: 0.05891 | val_0_rmse: 0.08336 | val_0_mse: 0.00695 |  0:07:20s\n",
            "epoch 486| loss: 0.00895 | val_0_mae: 0.05842 | val_0_rmse: 0.08264 | val_0_mse: 0.00683 |  0:07:21s\n",
            "epoch 487| loss: 0.00885 | val_0_mae: 0.05906 | val_0_rmse: 0.08354 | val_0_mse: 0.00698 |  0:07:23s\n",
            "epoch 488| loss: 0.00892 | val_0_mae: 0.0597  | val_0_rmse: 0.08349 | val_0_mse: 0.00697 |  0:07:23s\n",
            "epoch 489| loss: 0.00883 | val_0_mae: 0.06036 | val_0_rmse: 0.08507 | val_0_mse: 0.00724 |  0:07:24s\n",
            "epoch 490| loss: 0.00891 | val_0_mae: 0.06105 | val_0_rmse: 0.08452 | val_0_mse: 0.00714 |  0:07:25s\n",
            "epoch 491| loss: 0.00893 | val_0_mae: 0.05869 | val_0_rmse: 0.08303 | val_0_mse: 0.00689 |  0:07:26s\n",
            "epoch 492| loss: 0.00886 | val_0_mae: 0.05877 | val_0_rmse: 0.08291 | val_0_mse: 0.00687 |  0:07:27s\n",
            "epoch 493| loss: 0.00887 | val_0_mae: 0.06284 | val_0_rmse: 0.08613 | val_0_mse: 0.00742 |  0:07:27s\n",
            "epoch 494| loss: 0.00898 | val_0_mae: 0.0588  | val_0_rmse: 0.08291 | val_0_mse: 0.00687 |  0:07:28s\n",
            "epoch 495| loss: 0.00894 | val_0_mae: 0.05874 | val_0_rmse: 0.08317 | val_0_mse: 0.00692 |  0:07:29s\n",
            "epoch 496| loss: 0.00894 | val_0_mae: 0.05917 | val_0_rmse: 0.08357 | val_0_mse: 0.00698 |  0:07:30s\n",
            "epoch 497| loss: 0.00895 | val_0_mae: 0.05876 | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:07:30s\n",
            "epoch 498| loss: 0.0088  | val_0_mae: 0.0585  | val_0_rmse: 0.08271 | val_0_mse: 0.00684 |  0:07:31s\n",
            "epoch 499| loss: 0.00889 | val_0_mae: 0.05939 | val_0_rmse: 0.08341 | val_0_mse: 0.00696 |  0:07:32s\n",
            "epoch 500| loss: 0.00883 | val_0_mae: 0.05854 | val_0_rmse: 0.08291 | val_0_mse: 0.00687 |  0:07:33s\n",
            "epoch 501| loss: 0.00883 | val_0_mae: 0.06104 | val_0_rmse: 0.08425 | val_0_mse: 0.0071  |  0:07:34s\n",
            "epoch 502| loss: 0.0089  | val_0_mae: 0.05946 | val_0_rmse: 0.08375 | val_0_mse: 0.00701 |  0:07:35s\n",
            "epoch 503| loss: 0.00895 | val_0_mae: 0.05908 | val_0_rmse: 0.08373 | val_0_mse: 0.00701 |  0:07:36s\n",
            "epoch 504| loss: 0.00894 | val_0_mae: 0.0586  | val_0_rmse: 0.08289 | val_0_mse: 0.00687 |  0:07:37s\n",
            "epoch 505| loss: 0.00894 | val_0_mae: 0.05917 | val_0_rmse: 0.08315 | val_0_mse: 0.00691 |  0:07:38s\n",
            "epoch 506| loss: 0.00896 | val_0_mae: 0.0595  | val_0_rmse: 0.08414 | val_0_mse: 0.00708 |  0:07:39s\n",
            "epoch 507| loss: 0.00892 | val_0_mae: 0.05877 | val_0_rmse: 0.08307 | val_0_mse: 0.0069  |  0:07:39s\n",
            "epoch 508| loss: 0.00896 | val_0_mae: 0.05974 | val_0_rmse: 0.0845  | val_0_mse: 0.00714 |  0:07:40s\n",
            "epoch 509| loss: 0.00911 | val_0_mae: 0.06168 | val_0_rmse: 0.0865  | val_0_mse: 0.00748 |  0:07:41s\n",
            "epoch 510| loss: 0.00888 | val_0_mae: 0.05979 | val_0_rmse: 0.08314 | val_0_mse: 0.00691 |  0:07:42s\n",
            "epoch 511| loss: 0.00891 | val_0_mae: 0.05861 | val_0_rmse: 0.08264 | val_0_mse: 0.00683 |  0:07:42s\n",
            "epoch 512| loss: 0.00886 | val_0_mae: 0.05899 | val_0_rmse: 0.08308 | val_0_mse: 0.0069  |  0:07:43s\n",
            "epoch 513| loss: 0.00889 | val_0_mae: 0.05961 | val_0_rmse: 0.08421 | val_0_mse: 0.00709 |  0:07:44s\n",
            "epoch 514| loss: 0.0089  | val_0_mae: 0.05889 | val_0_rmse: 0.08295 | val_0_mse: 0.00688 |  0:07:45s\n",
            "epoch 515| loss: 0.00894 | val_0_mae: 0.05941 | val_0_rmse: 0.08375 | val_0_mse: 0.00701 |  0:07:45s\n",
            "epoch 516| loss: 0.00899 | val_0_mae: 0.05987 | val_0_rmse: 0.08441 | val_0_mse: 0.00713 |  0:07:46s\n",
            "epoch 517| loss: 0.00894 | val_0_mae: 0.05885 | val_0_rmse: 0.08307 | val_0_mse: 0.0069  |  0:07:47s\n",
            "epoch 518| loss: 0.00883 | val_0_mae: 0.05865 | val_0_rmse: 0.08275 | val_0_mse: 0.00685 |  0:07:48s\n",
            "epoch 519| loss: 0.00887 | val_0_mae: 0.05867 | val_0_rmse: 0.08273 | val_0_mse: 0.00684 |  0:07:50s\n",
            "epoch 520| loss: 0.00889 | val_0_mae: 0.06024 | val_0_rmse: 0.08479 | val_0_mse: 0.00719 |  0:07:51s\n",
            "epoch 521| loss: 0.00889 | val_0_mae: 0.05915 | val_0_rmse: 0.08357 | val_0_mse: 0.00698 |  0:07:51s\n",
            "epoch 522| loss: 0.00893 | val_0_mae: 0.05879 | val_0_rmse: 0.08262 | val_0_mse: 0.00683 |  0:07:52s\n",
            "epoch 523| loss: 0.00893 | val_0_mae: 0.05883 | val_0_rmse: 0.08285 | val_0_mse: 0.00686 |  0:07:53s\n",
            "epoch 524| loss: 0.00892 | val_0_mae: 0.05924 | val_0_rmse: 0.08357 | val_0_mse: 0.00698 |  0:07:54s\n",
            "epoch 525| loss: 0.00892 | val_0_mae: 0.06014 | val_0_rmse: 0.08348 | val_0_mse: 0.00697 |  0:07:54s\n",
            "epoch 526| loss: 0.00891 | val_0_mae: 0.05888 | val_0_rmse: 0.08316 | val_0_mse: 0.00691 |  0:07:55s\n",
            "epoch 527| loss: 0.00891 | val_0_mae: 0.05878 | val_0_rmse: 0.0826  | val_0_mse: 0.00682 |  0:07:56s\n",
            "epoch 528| loss: 0.00893 | val_0_mae: 0.05864 | val_0_rmse: 0.08245 | val_0_mse: 0.0068  |  0:07:57s\n",
            "epoch 529| loss: 0.00891 | val_0_mae: 0.05874 | val_0_rmse: 0.08295 | val_0_mse: 0.00688 |  0:07:58s\n",
            "epoch 530| loss: 0.00894 | val_0_mae: 0.05891 | val_0_rmse: 0.08256 | val_0_mse: 0.00682 |  0:07:58s\n",
            "epoch 531| loss: 0.00883 | val_0_mae: 0.05891 | val_0_rmse: 0.08313 | val_0_mse: 0.00691 |  0:07:59s\n",
            "epoch 532| loss: 0.00887 | val_0_mae: 0.05885 | val_0_rmse: 0.08262 | val_0_mse: 0.00683 |  0:08:00s\n",
            "epoch 533| loss: 0.00884 | val_0_mae: 0.05892 | val_0_rmse: 0.08306 | val_0_mse: 0.0069  |  0:08:01s\n",
            "epoch 534| loss: 0.00886 | val_0_mae: 0.05981 | val_0_rmse: 0.08319 | val_0_mse: 0.00692 |  0:08:02s\n",
            "epoch 535| loss: 0.00892 | val_0_mae: 0.05882 | val_0_rmse: 0.08291 | val_0_mse: 0.00687 |  0:08:03s\n",
            "epoch 536| loss: 0.00885 | val_0_mae: 0.05865 | val_0_rmse: 0.08255 | val_0_mse: 0.00682 |  0:08:04s\n",
            "epoch 537| loss: 0.00897 | val_0_mae: 0.05879 | val_0_rmse: 0.08216 | val_0_mse: 0.00675 |  0:08:05s\n",
            "epoch 538| loss: 0.00897 | val_0_mae: 0.05878 | val_0_rmse: 0.08277 | val_0_mse: 0.00685 |  0:08:06s\n",
            "epoch 539| loss: 0.0089  | val_0_mae: 0.059   | val_0_rmse: 0.08317 | val_0_mse: 0.00692 |  0:08:07s\n",
            "epoch 540| loss: 0.00903 | val_0_mae: 0.05909 | val_0_rmse: 0.08335 | val_0_mse: 0.00695 |  0:08:07s\n",
            "epoch 541| loss: 0.00898 | val_0_mae: 0.05883 | val_0_rmse: 0.08273 | val_0_mse: 0.00684 |  0:08:08s\n",
            "epoch 542| loss: 0.00889 | val_0_mae: 0.05998 | val_0_rmse: 0.0834  | val_0_mse: 0.00695 |  0:08:09s\n",
            "epoch 543| loss: 0.00894 | val_0_mae: 0.05883 | val_0_rmse: 0.08306 | val_0_mse: 0.0069  |  0:08:10s\n",
            "epoch 544| loss: 0.00888 | val_0_mae: 0.05875 | val_0_rmse: 0.08278 | val_0_mse: 0.00685 |  0:08:10s\n",
            "epoch 545| loss: 0.00892 | val_0_mae: 0.05903 | val_0_rmse: 0.08324 | val_0_mse: 0.00693 |  0:08:11s\n",
            "epoch 546| loss: 0.00882 | val_0_mae: 0.05943 | val_0_rmse: 0.08293 | val_0_mse: 0.00688 |  0:08:12s\n",
            "epoch 547| loss: 0.00886 | val_0_mae: 0.05881 | val_0_rmse: 0.08292 | val_0_mse: 0.00688 |  0:08:13s\n",
            "epoch 548| loss: 0.00889 | val_0_mae: 0.05985 | val_0_rmse: 0.08348 | val_0_mse: 0.00697 |  0:08:14s\n",
            "epoch 549| loss: 0.009   | val_0_mae: 0.0607  | val_0_rmse: 0.08516 | val_0_mse: 0.00725 |  0:08:15s\n",
            "epoch 550| loss: 0.00902 | val_0_mae: 0.05895 | val_0_rmse: 0.08303 | val_0_mse: 0.00689 |  0:08:16s\n",
            "epoch 551| loss: 0.00879 | val_0_mae: 0.05905 | val_0_rmse: 0.0833  | val_0_mse: 0.00694 |  0:08:17s\n",
            "epoch 552| loss: 0.00881 | val_0_mae: 0.05939 | val_0_rmse: 0.08366 | val_0_mse: 0.007   |  0:08:18s\n",
            "epoch 553| loss: 0.00885 | val_0_mae: 0.05902 | val_0_rmse: 0.08318 | val_0_mse: 0.00692 |  0:08:19s\n",
            "epoch 554| loss: 0.00888 | val_0_mae: 0.05992 | val_0_rmse: 0.08442 | val_0_mse: 0.00713 |  0:08:20s\n",
            "epoch 555| loss: 0.00897 | val_0_mae: 0.06056 | val_0_rmse: 0.08396 | val_0_mse: 0.00705 |  0:08:20s\n",
            "epoch 556| loss: 0.00885 | val_0_mae: 0.0595  | val_0_rmse: 0.08386 | val_0_mse: 0.00703 |  0:08:21s\n",
            "epoch 557| loss: 0.0089  | val_0_mae: 0.05914 | val_0_rmse: 0.08341 | val_0_mse: 0.00696 |  0:08:22s\n",
            "epoch 558| loss: 0.00888 | val_0_mae: 0.05893 | val_0_rmse: 0.08301 | val_0_mse: 0.00689 |  0:08:23s\n",
            "epoch 559| loss: 0.00877 | val_0_mae: 0.05903 | val_0_rmse: 0.08292 | val_0_mse: 0.00688 |  0:08:23s\n",
            "epoch 560| loss: 0.00883 | val_0_mae: 0.05995 | val_0_rmse: 0.08345 | val_0_mse: 0.00696 |  0:08:24s\n",
            "epoch 561| loss: 0.0089  | val_0_mae: 0.05916 | val_0_rmse: 0.08291 | val_0_mse: 0.00687 |  0:08:25s\n",
            "epoch 562| loss: 0.00888 | val_0_mae: 0.0611  | val_0_rmse: 0.08566 | val_0_mse: 0.00734 |  0:08:26s\n",
            "epoch 563| loss: 0.00893 | val_0_mae: 0.05868 | val_0_rmse: 0.08264 | val_0_mse: 0.00683 |  0:08:26s\n",
            "epoch 564| loss: 0.00878 | val_0_mae: 0.05996 | val_0_rmse: 0.08338 | val_0_mse: 0.00695 |  0:08:27s\n",
            "epoch 565| loss: 0.00888 | val_0_mae: 0.05962 | val_0_rmse: 0.08332 | val_0_mse: 0.00694 |  0:08:28s\n",
            "epoch 566| loss: 0.00886 | val_0_mae: 0.05883 | val_0_rmse: 0.08297 | val_0_mse: 0.00688 |  0:08:29s\n",
            "epoch 567| loss: 0.00899 | val_0_mae: 0.05913 | val_0_rmse: 0.08303 | val_0_mse: 0.00689 |  0:08:30s\n",
            "epoch 568| loss: 0.00887 | val_0_mae: 0.06001 | val_0_rmse: 0.08457 | val_0_mse: 0.00715 |  0:08:31s\n",
            "epoch 569| loss: 0.00904 | val_0_mae: 0.05908 | val_0_rmse: 0.08287 | val_0_mse: 0.00687 |  0:08:32s\n",
            "epoch 570| loss: 0.00901 | val_0_mae: 0.05887 | val_0_rmse: 0.08295 | val_0_mse: 0.00688 |  0:08:33s\n",
            "epoch 571| loss: 0.00878 | val_0_mae: 0.05877 | val_0_rmse: 0.08284 | val_0_mse: 0.00686 |  0:08:34s\n",
            "epoch 572| loss: 0.0089  | val_0_mae: 0.05993 | val_0_rmse: 0.08441 | val_0_mse: 0.00713 |  0:08:35s\n",
            "epoch 573| loss: 0.00888 | val_0_mae: 0.06023 | val_0_rmse: 0.08452 | val_0_mse: 0.00714 |  0:08:35s\n",
            "epoch 574| loss: 0.00888 | val_0_mae: 0.05897 | val_0_rmse: 0.08314 | val_0_mse: 0.00691 |  0:08:36s\n",
            "epoch 575| loss: 0.00889 | val_0_mae: 0.06048 | val_0_rmse: 0.08379 | val_0_mse: 0.00702 |  0:08:37s\n",
            "epoch 576| loss: 0.00894 | val_0_mae: 0.05992 | val_0_rmse: 0.08429 | val_0_mse: 0.00711 |  0:08:38s\n",
            "epoch 577| loss: 0.00889 | val_0_mae: 0.05866 | val_0_rmse: 0.08263 | val_0_mse: 0.00683 |  0:08:39s\n",
            "epoch 578| loss: 0.00885 | val_0_mae: 0.05885 | val_0_rmse: 0.08266 | val_0_mse: 0.00683 |  0:08:39s\n",
            "epoch 579| loss: 0.0089  | val_0_mae: 0.05881 | val_0_rmse: 0.08292 | val_0_mse: 0.00687 |  0:08:40s\n",
            "epoch 580| loss: 0.00886 | val_0_mae: 0.05883 | val_0_rmse: 0.08295 | val_0_mse: 0.00688 |  0:08:41s\n",
            "epoch 581| loss: 0.00891 | val_0_mae: 0.05877 | val_0_rmse: 0.0829  | val_0_mse: 0.00687 |  0:08:42s\n",
            "epoch 582| loss: 0.0088  | val_0_mae: 0.05904 | val_0_rmse: 0.08298 | val_0_mse: 0.00689 |  0:08:43s\n",
            "epoch 583| loss: 0.00885 | val_0_mae: 0.05909 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:08:45s\n",
            "epoch 584| loss: 0.00893 | val_0_mae: 0.0589  | val_0_rmse: 0.0831  | val_0_mse: 0.00691 |  0:08:46s\n",
            "epoch 585| loss: 0.00878 | val_0_mae: 0.05959 | val_0_rmse: 0.0832  | val_0_mse: 0.00692 |  0:08:46s\n",
            "epoch 586| loss: 0.00873 | val_0_mae: 0.05903 | val_0_rmse: 0.08312 | val_0_mse: 0.00691 |  0:08:47s\n",
            "epoch 587| loss: 0.00887 | val_0_mae: 0.05875 | val_0_rmse: 0.08291 | val_0_mse: 0.00687 |  0:08:48s\n",
            "epoch 588| loss: 0.00892 | val_0_mae: 0.06024 | val_0_rmse: 0.08359 | val_0_mse: 0.00699 |  0:08:49s\n",
            "epoch 589| loss: 0.00892 | val_0_mae: 0.05884 | val_0_rmse: 0.08296 | val_0_mse: 0.00688 |  0:08:50s\n",
            "epoch 590| loss: 0.00884 | val_0_mae: 0.05857 | val_0_rmse: 0.08275 | val_0_mse: 0.00685 |  0:08:50s\n",
            "epoch 591| loss: 0.00884 | val_0_mae: 0.05949 | val_0_rmse: 0.08392 | val_0_mse: 0.00704 |  0:08:51s\n",
            "epoch 592| loss: 0.00894 | val_0_mae: 0.05863 | val_0_rmse: 0.08282 | val_0_mse: 0.00686 |  0:08:52s\n",
            "epoch 593| loss: 0.00893 | val_0_mae: 0.05893 | val_0_rmse: 0.08323 | val_0_mse: 0.00693 |  0:08:53s\n",
            "epoch 594| loss: 0.009   | val_0_mae: 0.05979 | val_0_rmse: 0.08326 | val_0_mse: 0.00693 |  0:08:54s\n",
            "epoch 595| loss: 0.00888 | val_0_mae: 0.05914 | val_0_rmse: 0.08293 | val_0_mse: 0.00688 |  0:08:54s\n",
            "epoch 596| loss: 0.00884 | val_0_mae: 0.05861 | val_0_rmse: 0.08269 | val_0_mse: 0.00684 |  0:08:55s\n",
            "\n",
            "Early stopping occurred at epoch 596 with best_epoch = 96 and best_val_0_mse = 0.00674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "## Generate Predictions on Test Set: Use the trained model to predict y_test and get the scaled predictions.\n",
        "## Inverse Transform the Predictions: Transform the scaled predictions back to the original target scale using the scaler_y.inverse_transform() method.\n",
        "## Evaluate Performance: Use evaluation metrics like R² (for regression accuracy) to assess model performance."
      ],
      "metadata": {
        "id": "KQOqY1rK08jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZltoDmc5fLv",
        "outputId": "fb0c3c23-78c4-4c1c-c9a5-8f39f0d62a33"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44921158],\n",
              "       [0.47131128],\n",
              "       [0.58388977],\n",
              "       ...,\n",
              "       [0.44683485],\n",
              "       [0.49315005],\n",
              "       [0.41515887]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test set\n",
        "y_pred = tabnet_model.predict(X_test_np)\n",
        "\n",
        "y_pred_real = scaler_y.inverse_transform(y_pred)\n",
        "\n",
        "# Evaluate the model using R² score\n",
        "r2 = r2_score(y_test, y_pred_real)\n",
        "print(f\"R² Score: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saRg1zFq1AED",
        "outputId": "63235392-8deb-46b9-80c4-7548dcba7de0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.017700444810294536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"######## Y testing before scaling (original) ########\")\n",
        "print(y_test.describe())\n",
        "print(\"######## Y testing after scaling ####################\")\n",
        "print(pd.DataFrame(y_test_scaled).describe())\n",
        "print(\"######## Y prediction before rescaling ##############\")\n",
        "print(pd.DataFrame(y_pred).describe())\n",
        "print(\"######## Y prediction after rescaling ###############\")\n",
        "print(pd.DataFrame(y_pred_real).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0WmrAjDj5_Ul",
        "outputId": "f2eb8179-a10b-4d2e-d553-502ae82c713a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Y testing before scaling (original) ########\n",
            "count    1447.000000\n",
            "mean        0.025506\n",
            "std         0.149190\n",
            "min        -0.836655\n",
            "25%        -0.060109\n",
            "50%         0.018869\n",
            "75%         0.105390\n",
            "max         2.229665\n",
            "Name: return, dtype: float64\n",
            "######## Y testing after scaling ####################\n",
            "                 0\n",
            "count  1447.000000\n",
            "mean      0.465263\n",
            "std       0.082844\n",
            "min      -0.013490\n",
            "25%       0.417722\n",
            "50%       0.461578\n",
            "75%       0.509623\n",
            "max       1.689222\n",
            "######## Y prediction before rescaling ##############\n",
            "                 0\n",
            "count  1447.000000\n",
            "mean      0.461570\n",
            "std       0.008915\n",
            "min       0.437716\n",
            "25%       0.459430\n",
            "50%       0.460217\n",
            "75%       0.461672\n",
            "max       0.724138\n",
            "######## Y prediction after rescaling ###############\n",
            "                 0\n",
            "count  1447.000000\n",
            "mean      0.018854\n",
            "std       0.016055\n",
            "min      -0.024103\n",
            "25%       0.015002\n",
            "50%       0.016419\n",
            "75%       0.019039\n",
            "max       0.491699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZbeB8IR54PY",
        "outputId": "e5498c59-3473-43e6-f1e4-b9a92f4588a3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.464327  ],\n",
              "       [0.46419102],\n",
              "       [0.4639785 ],\n",
              "       ...,\n",
              "       [0.4642815 ],\n",
              "       [0.46413696],\n",
              "       [0.4641221 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Prediction on Real Data\n",
        "\n",
        "## Prepare New Data: When using new data for live predictions (e.g., current quarter data), follow the same preprocessing steps (dropping unnecessary columns, scaling).\n",
        "## Generate Predictions: Use the trained model to make predictions on this new, unseen data.\n",
        "## Inverse Transform for Real Values: Convert these predictions back to the original scale to get the actual return values"
      ],
      "metadata": {
        "id": "j5kLxIMI1GoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KeP_xKuA1K9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleRNN\n",
        "## Build SimpleRNN from keras to make a regression prediction.\n"
      ],
      "metadata": {
        "id": "2k-HrSpzDFJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n_samples = X_train_scaled.shape[0]\n",
        "n_timesteps = X_train_scaled.shape[1]\n",
        "n_steps = y_train_scaled.shape[1]\n",
        "n_features = 1\n",
        "X_train_rs = X_train_np.reshape(n_samples, n_timesteps, n_features )\n",
        "X_test_rs = X_test_np.reshape(X_test_scaled.shape[0], n_timesteps, n_features )"
      ],
      "metadata": {
        "id": "ECLs1__sEd-A"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define the Simple RNN model\n",
        "simple_model = Sequential([\n",
        "    SimpleRNN(8, activation='tanh', input_shape=(n_timesteps, n_features)),\n",
        "    Dense(1)  # Single output node for return prediction\n",
        "])\n",
        "\n",
        "simple_model.summary()\n",
        "\n",
        "# Compile the model\n",
        "simple_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mean_absolute_error',  # MAE loss function\n",
        "    metrics=['mean_absolute_error']  # Track MAE during training\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "smod_history = simple_model.fit(\n",
        "    X_train_rs, y_train_scaled,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,  # Increased number of epochs for better learning\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Predict on the test set\n",
        "preds_scaled = simple_model.predict(X_test_rs)\n",
        "\n",
        "# Reverse scaling of predictions and actual values\n",
        "preds = scaler_y.inverse_transform(preds_scaled)  # Assuming `scaler_y` is your y-target scaler\n",
        "# y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calculate R² score\n",
        "r2 = r2_score(y_test, preds)\n",
        "print(\"R² score:\", r2)\n",
        "\n",
        "# Plot training & validation loss history\n",
        "plt.plot(smod_history.history['loss'], label='Training Loss')\n",
        "plt.plot(smod_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss During Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "OigR_o-wDHfL",
        "outputId": "ec89479e-e4e5-46b3-e51c-cc68a3747b8b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89\u001b[0m (356.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89</span> (356.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89\u001b[0m (356.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89</span> (356.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0875 - mean_absolute_error: 0.0875 - val_loss: 0.0779 - val_mean_absolute_error: 0.0779\n",
            "Epoch 2/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 3/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0691 - mean_absolute_error: 0.0691 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 4/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0691 - mean_absolute_error: 0.0691 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 5/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 6/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 7/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0690 - mean_absolute_error: 0.0690 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 8/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0689 - mean_absolute_error: 0.0689 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n",
            "Epoch 9/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n",
            "Epoch 10/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 11/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0689 - mean_absolute_error: 0.0689 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 12/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 13/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 14/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 15/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 16/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 17/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 18/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 19/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 20/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 21/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 22/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0789 - val_mean_absolute_error: 0.0789\n",
            "Epoch 23/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0688 - mean_absolute_error: 0.0688 - val_loss: 0.0778 - val_mean_absolute_error: 0.0778\n",
            "Epoch 24/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0789 - val_mean_absolute_error: 0.0789\n",
            "Epoch 25/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 26/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0788 - val_mean_absolute_error: 0.0788\n",
            "Epoch 27/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n",
            "Epoch 28/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0791 - val_mean_absolute_error: 0.0791\n",
            "Epoch 29/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - mean_absolute_error: 0.0687 - val_loss: 0.0787 - val_mean_absolute_error: 0.0787\n",
            "Epoch 30/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 31/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 32/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 33/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 34/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0786 - val_mean_absolute_error: 0.0786\n",
            "Epoch 35/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0686 - mean_absolute_error: 0.0686 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 36/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 37/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n",
            "Epoch 38/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 39/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 40/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0784 - val_mean_absolute_error: 0.0784\n",
            "Epoch 41/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 42/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 43/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 44/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 45/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0685 - mean_absolute_error: 0.0685 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n",
            "Epoch 46/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 47/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 48/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0781 - val_mean_absolute_error: 0.0781\n",
            "Epoch 49/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 50/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "R² score: -0.039839778441993046\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(preds).describe())\n",
        "print(pd.DataFrame(preds_scaled).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edXxKEMmGUsP",
        "outputId": "3d477df8-9ce5-4518-93c8-ee42809bd052"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0\n",
            "count  1447.000000\n",
            "mean     -0.004376\n",
            "std       0.009834\n",
            "min      -0.307941\n",
            "25%      -0.004671\n",
            "50%      -0.004355\n",
            "75%      -0.003930\n",
            "max       0.126289\n",
            "                 0\n",
            "count  1447.000000\n",
            "mean      0.448670\n",
            "std       0.005461\n",
            "min       0.280102\n",
            "25%       0.448506\n",
            "50%       0.448682\n",
            "75%       0.448917\n",
            "max       0.521227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleRNN might be too simple for my datatype"
      ],
      "metadata": {
        "id": "DFB-JQkmH_5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Personal builded LSTM"
      ],
      "metadata": {
        "id": "hIsP8xqHTHcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "00N_lWbgTiAI"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(100, activation='tanh', return_sequences=True, input_shape=(n_timesteps, n_features)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(75, activation='tanh', return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='tanh', return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='tanh', return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='tanh', return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='tanh', return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(25, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Output layer for regression (single output for return prediction)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Albb4ltIGhVQ",
        "outputId": "0788f628-a519-4561-e2af-c2728ac0f4ba"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m46,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m75\u001b[0m)               │          \u001b[38;5;34m52,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m75\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m25,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m7,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m26\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">46,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">52,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m192,626\u001b[0m (752.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,626</span> (752.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m192,626\u001b[0m (752.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,626</span> (752.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - loss: 0.1100 - mean_absolute_error: 0.2773 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 2/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0111 - mean_absolute_error: 0.0812 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 3/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0110 - mean_absolute_error: 0.0798 - val_loss: 0.0114 - val_mean_absolute_error: 0.0775\n",
            "Epoch 4/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0110 - mean_absolute_error: 0.0794 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 5/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mean_absolute_error: 0.0794 - val_loss: 0.0113 - val_mean_absolute_error: 0.0773\n",
            "Epoch 6/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0105 - mean_absolute_error: 0.0778 - val_loss: 0.0114 - val_mean_absolute_error: 0.0775\n",
            "Epoch 7/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0101 - mean_absolute_error: 0.0762 - val_loss: 0.0114 - val_mean_absolute_error: 0.0777\n",
            "Epoch 8/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0103 - mean_absolute_error: 0.0776 - val_loss: 0.0114 - val_mean_absolute_error: 0.0778\n",
            "Epoch 9/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0100 - mean_absolute_error: 0.0757 - val_loss: 0.0115 - val_mean_absolute_error: 0.0780\n",
            "Epoch 10/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0098 - mean_absolute_error: 0.0750 - val_loss: 0.0115 - val_mean_absolute_error: 0.0779\n",
            "Epoch 11/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0098 - mean_absolute_error: 0.0745 - val_loss: 0.0115 - val_mean_absolute_error: 0.0779\n",
            "Epoch 12/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0097 - mean_absolute_error: 0.0750 - val_loss: 0.0114 - val_mean_absolute_error: 0.0777\n",
            "Epoch 13/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0096 - mean_absolute_error: 0.0737 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 14/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0095 - mean_absolute_error: 0.0732 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 15/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0092 - mean_absolute_error: 0.0725 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 16/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0093 - mean_absolute_error: 0.0726 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 17/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0093 - mean_absolute_error: 0.0723 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 18/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0091 - mean_absolute_error: 0.0717 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 19/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0091 - mean_absolute_error: 0.0713 - val_loss: 0.0113 - val_mean_absolute_error: 0.0772\n",
            "Epoch 20/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0092 - mean_absolute_error: 0.0716 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 21/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0090 - mean_absolute_error: 0.0710 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 22/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0090 - mean_absolute_error: 0.0710 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 23/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0089 - mean_absolute_error: 0.0708 - val_loss: 0.0112 - val_mean_absolute_error: 0.0770\n",
            "Epoch 24/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0090 - mean_absolute_error: 0.0711 - val_loss: 0.0112 - val_mean_absolute_error: 0.0771\n",
            "Epoch 25/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0089 - mean_absolute_error: 0.0703 - val_loss: 0.0112 - val_mean_absolute_error: 0.0770\n",
            "Epoch 26/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0089 - mean_absolute_error: 0.0707 - val_loss: 0.0111 - val_mean_absolute_error: 0.0769\n",
            "Epoch 27/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0088 - mean_absolute_error: 0.0701 - val_loss: 0.0111 - val_mean_absolute_error: 0.0769\n",
            "Epoch 28/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0697 - val_loss: 0.0112 - val_mean_absolute_error: 0.0769\n",
            "Epoch 29/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0699 - val_loss: 0.0112 - val_mean_absolute_error: 0.0769\n",
            "Epoch 30/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0087 - mean_absolute_error: 0.0696 - val_loss: 0.0112 - val_mean_absolute_error: 0.0770\n",
            "Epoch 31/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0087 - mean_absolute_error: 0.0697 - val_loss: 0.0112 - val_mean_absolute_error: 0.0769\n",
            "Epoch 32/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0696 - val_loss: 0.0112 - val_mean_absolute_error: 0.0769\n",
            "Epoch 33/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0694 - val_loss: 0.0111 - val_mean_absolute_error: 0.0769\n",
            "Epoch 34/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0695 - val_loss: 0.0112 - val_mean_absolute_error: 0.0769\n",
            "Epoch 35/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0696 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 36/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0695 - val_loss: 0.0112 - val_mean_absolute_error: 0.0769\n",
            "Epoch 37/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0087 - mean_absolute_error: 0.0695 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 38/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0694 - val_loss: 0.0111 - val_mean_absolute_error: 0.0769\n",
            "Epoch 39/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0086 - mean_absolute_error: 0.0691 - val_loss: 0.0111 - val_mean_absolute_error: 0.0769\n",
            "Epoch 40/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mean_absolute_error: 0.0693 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 41/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0086 - mean_absolute_error: 0.0692 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 42/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0086 - mean_absolute_error: 0.0692 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 43/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0086 - mean_absolute_error: 0.0694 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 44/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0086 - mean_absolute_error: 0.0690 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 45/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0086 - mean_absolute_error: 0.0691 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 46/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0086 - mean_absolute_error: 0.0692 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 47/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0086 - mean_absolute_error: 0.0693 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 48/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0086 - mean_absolute_error: 0.0690 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 49/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0086 - mean_absolute_error: 0.0691 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n",
            "Epoch 50/50\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0086 - mean_absolute_error: 0.0691 - val_loss: 0.0111 - val_mean_absolute_error: 0.0768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Rescale predictions and actual values back to original scale\n",
        "num_original_features = 16\n",
        "y_pred = scaler.inverse_transform(np.concatenate([np.zeros((y_pred_scaled.shape[0], num_original_features - 1)), y_pred_scaled], axis=1))[:, -1]\n",
        "y_test_original = scaler.inverse_transform(np.concatenate([np.zeros((y_test.shape[0], num_original_features - 1)), y_test.reshape(-1, 1)], axis=1))[:, -1]\n",
        "\n",
        "# Evaluate the model using R² score\n",
        "r2 = r2_score(y_test_original, y_pred)\n",
        "print(f'R² Score: {r2}')\n",
        "\n",
        "# Plot training loss and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "3_wHgBhLTdk-",
        "outputId": "ab7f37e8-bc72-48bb-99f6-171edcefc5f2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "R² Score: -0.000497158676563414\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_pred_scaled).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BV7J-DiZVN9H",
        "outputId": "8410dca1-5df3-4892-c8d6-626526a6e538"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0\n",
              "count  1.445000e+03\n",
              "mean   4.634221e-01\n",
              "std    3.941611e-07\n",
              "min    4.634101e-01\n",
              "25%    4.634221e-01\n",
              "50%    4.634221e-01\n",
              "75%    4.634221e-01\n",
              "max    4.634228e-01"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b2a8f02-a3dd-478e-832d-abfa19f43dc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.445000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.634221e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.941611e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.634101e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.634221e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.634221e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.634221e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.634228e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b2a8f02-a3dd-478e-832d-abfa19f43dc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b2a8f02-a3dd-478e-832d-abfa19f43dc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b2a8f02-a3dd-478e-832d-abfa19f43dc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67b04d09-05e5-47b8-91e7-c1961b96dfd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67b04d09-05e5-47b8-91e7-c1961b96dfd3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67b04d09-05e5-47b8-91e7-c1961b96dfd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 510.74423760209277,\n        \"min\": 3.941610771107662e-07,\n        \"max\": 1445.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1445.0,\n          0.4634220600128174,\n          0.4634227752685547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UteC24OcVlwL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}